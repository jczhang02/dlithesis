@inproceedings{long2018pde,
  title         = {Pde-net: Learning pdes from data},
  author        = {Long, Zichao and Lu, Yiping and Ma, Xianzhong and Dong, Bin},
  booktitle     = {International conference on machine learning},
  pages         = {3208--3216},
  year          = {2018},
  organization  = {PMLR}
}
@article{ershkov2021towards,
  title         = {Towards understanding the algorithms for solving the Navier--Stokes equations},
  author        = {Ershkov, Sergey V and Prosviryakov, Evgeniy Yu and Burmasheva, Natalya V and Christianto, Victor},
  journal       = {Fluid Dynamics Research},
  volume        = {53},
  number        = {4},
  pages         = {044501},
  year          = {2021},
  publisher     = {IOP Publishing}
}
@article{antonietti2020high,
  title         = {A high-order discontinuous Galerkin method for nonlinear sound waves},
  author        = {Antonietti, Paola F and Mazzieri, Ilario and Muhr, Markus and Nikoli{\'c}, Vanja and Wohlmuth, Barbara},
  journal       = {Journal of Computational Physics},
  volume        = {415},
  pages         = {109484},
  year          = {2020},
  publisher     = {Elsevier}
}
@inproceedings{hansen2023learning,
  title         = {Learning physical models that can respect conservation laws},
  author        = {Hansen, Derek and Maddix, Danielle C and Alizadeh, Shima and Gupta, Gaurav and Mahoney, Michael W},
  booktitle     = {International Conference on Machine Learning},
  pages         = {12469--12510},
  year          = {2023},
  organization  = {PMLR}
}
@article{szabo2021finite,
  title         = {Finite element analysis: Method, verification and validation},
  author        = {Szab{\'o}, Barna and Babu{\v{s}}ka, Ivo},
  year          = {2021},
  publisher     = {John Wiley \& Sons}
}
@book{gedney2022introduction,
  title         = {Introduction to the finite-difference time-domain (FDTD) method for electromagnetics},
  author        = {Gedney, Stephen},
  year          = {2022},
  publisher     = {Springer Nature}
}
@article{muhammad2021finite,
  title         = {Finite volume method for simulation of flowing fluid via OpenFOAM},
  author        = {Muhammad, Noor},
  journal       = {The European Physical Journal plus},
  volume        = {136},
  number        = {10},
  pages         = {1--22},
  year          = {2021},
  publisher     = {Springer}
}
@article{meuris2023machine,
  title         = {Machine-learning-based spectral methods for partial differential equations},
  author        = {Meuris, Brek and Qadeer, Saad and Stinis, Panos},
  journal       = {Scientific Reports},
  volume        = {13},
  number        = {1},
  pages         = {1739},
  year          = {2023},
  publisher     = {Nature Publishing Group UK London}
}
@article{welch2021using,
  title         = {Using HPC to Solve PDEs to Improve Weather Forecasting},
  author        = {Welch, Jaclyn and Bawa, Gurvir K},
  year          = {2021}
}
@article{glau2022deep,
  title         = {The deep parametric PDE method and applications to option pricing},
  author        = {Glau, Kathrin and Wunderlich, Linus},
  journal       = {Applied Mathematics and Computation},
  volume        = {432},
  pages         = {127355},
  year          = {2022},
  publisher     = {Elsevier}
}
@article{karniadakis2021physics,
  title         = {Physics-informed machine learning},
  author        = {Karniadakis, George Em and Kevrekidis, Ioannis G and Lu, Lu and Perdikaris, Paris and Wang, Sifan and Yang, Liu},
  journal       = {Nature Reviews Physics},
  volume        = {3},
  number        = {6},
  pages         = {422--440},
  year          = {2021},
  publisher     = {Nature Publishing Group}
}
@article{pinns,
  title         = {Physics-informed neural networks: A deep learning framework for solving forward and inverse problems involving nonlinear partial differential equations},
  author        = {Raissi, Maziar and Perdikaris, Paris and Karniadakis, George E},
  journal       = {Journal of Computational physics},
  volume        = {378},
  pages         = {686--707},
  year          = {2019},
  publisher     = {Elsevier}
}
@article{chen2020physics,
  title         = {Physics-informed neural networks for inverse problems in nano-optics and metamaterials},
  author        = {Chen, Yuyao and Lu, Lu and Karniadakis, George Em and Dal Negro, Luca},
  journal       = {Optics express},
  volume        = {28},
  number        = {8},
  pages         = {11618--11633},
  year          = {2020},
  publisher     = {Optica Publishing Group}
}
@article{jagtap2020adaptive,
  title         = {Adaptive activation functions accelerate convergence in deep and physics-informed neural networks},
  author        = {Jagtap, Ameya D and Kawaguchi, Kenji and Karniadakis, George Em},
  journal       = {Journal of Computational Physics},
  volume        = {404},
  pages         = {109136},
  year          = {2020},
  publisher     = {Elsevier}
}
@article{meng2020composite,
  title         = {A composite neural network that learns from multi-fidelity data: Application to function approximation and inverse PDE problems},
  author        = {Meng, Xuhui and Karniadakis, George Em},
  journal       = {Journal of Computational Physics},
  volume        = {401},
  pages         = {109020},
  year          = {2020},
  publisher     = {Elsevier}
}
@article{lu2021deepxde,
  title         = {DeepXDE: A deep learning library for solving differential equations},
  author        = {Lu, Lu and Meng, Xuhui and Mao, Zhiping and Karniadakis, George Em},
  journal       = {SIAM review},
  volume        = {63},
  number        = {1},
  pages         = {208--228},
  year          = {2021},
  publisher     = {SIAM}
}
@inproceedings{alet2019graph,
  title         = {Graph element networks: adaptive, structured computation and memory},
  author        = {Alet, Ferran and Jeewajee, Adarsh Keshav and Villalonga, Maria Bauza and Rodriguez, Alberto and Lozano-Perez, Tomas and Kaelbling, Leslie},
  booktitle     = {International Conference on Machine Learning},
  pages         = {212--222},
  year          = {2019},
  organization  = {PMLR}
}
@article{bhatnagar2019prediction,
  title         = {Prediction of aerodynamic flow fields using convolutional neural networks},
  author        = {Bhatnagar, Saakaar and Afshar, Yaser and Pan, Shaowu and Duraisamy, Karthik and Kaushik, Shailendra},
  journal       = {Computational Mechanics},
  volume        = {64},
  pages         = {525--545},
  year          = {2019},
  publisher     = {Springer}
}
@article{deeponet,
  title         = {Learning nonlinear operators via DeepONet based on the universal approximation theorem of operators},
  author        = {Lu, Lu and Jin, Pengzhan and Pang, Guofei and Zhang, Zhongqiang and Karniadakis, George Em},
  journal       = {Nature machine intelligence},
  volume        = {3},
  number        = {3},
  pages         = {218--229},
  year          = {2021},
  publisher     = {Nature Publishing Group UK London}
}
@article{li2020fourier,
  title         = {Fourier neural operator for parametric partial differential equations},
  author        = {Li, Zongyi and Kovachki, Nikola and Azizzadenesheli, Kamyar and Liu, Burigede and Bhattacharya, Kaushik and Stuart, Andrew and Anandkumar, Anima},
  journal       = {arXiv preprint arXiv:2010.08895},
  year          = {2020}
}
@article{pathak2022fourcastnet,
  title         = {Fourcastnet: A global data-driven high-resolution weather model using adaptive fourier neural operators},
  author        = {Pathak, Jaideep and Subramanian, Shashank and Harrington, Peter and Raja, Sanjeev and Chattopadhyay, Ashesh and Mardani, Morteza and Kurth, Thorsten and Hall, David and Li, Zongyi and Azizzadenesheli, Kamyar and Hassanzadeh, Pedram and Kashinath, Karthik and Anandkumar, Animashree},
  journal       = {arXiv preprint arXiv:2202.11214},
  year          = {2022}
}
@article{lam2022graphcast,
  title         = {GraphCast: Learning skillful medium-range global weather forecasting},
  author        = {Remi Lam and Alvaro Sanchez-Gonzalez and Matthew Willson and Peter Wirnsberger and Meire Fortunato and Alexander Pritzel and Suman Ravuri and Timo Ewalds and Ferran Alet and Zach Eaton-Rosen and Weihua Hu and Alexander Merose and Stephan Hoyer and George Holland and Jacklynn Stott and Oriol Vinyals and Shakir Mohamed and Peter Battaglia},
  year          = {2022},
  eprint        = {2212.12794},
  archiveprefix = {arXiv},
  primaryclass  = {cs.LG}
}
@misc{modulus,
  title         = {Modulus: An open-source framework for building, training, and fine-tuning Physics-ML models with a simple Python interface.},
  author        = {Nvidia Modulus team},
  url           = {https://developer.nvidia.com/modulus},
  year          = {2023}
}
@inproceedings{deng2009imagenet,
  title         = {Imagenet: A large-scale hierarchical image database},
  author        = {Deng, Jia and Dong, Wei and Socher, Richard and Li, Li-Jia and Li, Kai and Fei-Fei, Li},
  booktitle     = {2009 IEEE conference on computer vision and pattern recognition},
  pages         = {248--255},
  year          = {2009},
  organization  = {Ieee}
}
@article{alexnet,
  title         = {Imagenet classification with deep convolutional neural networks},
  author        = {Krizhevsky, Alex and Sutskever, Ilya and Hinton, Geoffrey E},
  journal       = {Advances in neural information processing systems},
  volume        = {25},
  year          = {2012}
}
@article{vgg,
  title         = {Very deep convolutional networks for large-scale image recognition},
  author        = {Simonyan, Karen and Zisserman, Andrew},
  journal       = {arXiv preprint arXiv:1409.1556},
  year          = {2014}
}
@inproceedings{resnet,
  title         = {Deep residual learning for image recognition},
  author        = {He, Kaiming and Zhang, Xiangyu and Ren, Shaoqing and Sun, Jian},
  booktitle     = {Proceedings of the IEEE conference on computer vision and pattern recognition},
  pages         = {770--778},
  year          = {2016}
}
@article{transformer,
  title         = {Attention is all you need},
  author        = {Vaswani, Ashish and Shazeer, Noam and Parmar, Niki and Uszkoreit, Jakob and Jones, Llion and Gomez, Aidan N and Kaiser, {\L}ukasz and Polosukhin, Illia},
  journal       = {Advances in neural information processing systems},
  volume        = {30},
  year          = {2017}
}
@article{cho2014learning,
  title         = {Learning phrase representations using RNN encoder-decoder for statistical machine translation},
  author        = {Cho, Kyunghyun and Van Merri{\"e}nboer, Bart and Gulcehre, Caglar and Bahdanau, Dzmitry and Bougares, Fethi and Schwenk, Holger and Bengio, Yoshua},
  journal       = {arXiv preprint arXiv:1406.1078},
  year          = {2014}
}
@article{paszke2019pytorch,
  title         = {Pytorch: An imperative style, high-performance deep learning library},
  author        = {Paszke, Adam and Gross, Sam and Massa, Francisco and Lerer, Adam and Bradbury, James and Chanan, Gregory and Killeen, Trevor and Lin, Zeming and Gimelshein, Natalia and Antiga, Luca and others},
  journal       = {Advances in neural information processing systems},
  volume        = {32},
  year          = {2019}
}
@inproceedings{jia2014caffe,
  title         = {Caffe: Convolutional architecture for fast feature embedding},
  author        = {Jia, Yangqing and Shelhamer, Evan and Donahue, Jeff and Karayev, Sergey and Long, Jonathan and Girshick, Ross and Guadarrama, Sergio and Darrell, Trevor},
  booktitle     = {Proceedings of the 22nd ACM international conference on Multimedia},
  pages         = {675--678},
  year          = {2014}
}
@article{abadi2016tensorflow,
  title         = {Tensorflow: Large-scale machine learning on heterogeneous distributed systems},
  author        = {Abadi, Mart{\'\i}n and Agarwal, Ashish and Barham, Paul and Brevdo, Eugene and Chen, Zhifeng and Citro, Craig and Corrado, Greg S and Davis, Andy and Dean, Jeffrey and Devin, Matthieu and others},
  journal       = {arXiv preprint arXiv:1603.04467},
  year          = {2016}
}
@article{mmdetection,
  title         = {{MMDetection}: Open MMLab Detection Toolbox and Benchmark},
  author        = {Chen, Kai and Wang, Jiaqi and Pang, Jiangmiao and Cao, Yuhang and Xiong, Yu and Li, Xiaoxiao and Sun, Shuyang and Feng, Wansen and Liu, Ziwei and Xu, Jiarui and Zhang, Zheng and Cheng, Dazhi and Zhu, Chenchen and Cheng, Tianheng and Zhao, Qijie and Li, Buyu and Lu, Xin and Zhu, Rui and Wu, Yue and Dai, Jifeng and Wang, Jingdong and Shi, Jianping and Ouyang, Wanli and Loy, Chen Change and Lin, Dahua},
  journal       = {arXiv preprint arXiv:1906.07155},
  year          = {2019}
}
@inproceedings{hu2023planning,
  title         = {Planning-oriented autonomous driving},
  author        = {Hu, Yihan and Yang, Jiazhi and Chen, Li and Li, Keyu and Sima, Chonghao and Zhu, Xizhou and Chai, Siqi and Du, Senyao and Lin, Tianwei and Wang, Wenhai and others},
  booktitle     = {Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages         = {17853--17862},
  year          = {2023}
}
@inproceedings{wang2021property,
  title         = {Property-Aware Relation Networks for Few-Shot Molecular Property Prediction},
  author        = {Wang, Yaqing and Abuduweili, Abulikemu and Yao, Quanming and Dou, Dejing},
  booktitle     = {Advances in Neural Information Processing Systems},
  year          = {2021}
}
@article{bryant2022improved,
  title         = {Improved prediction of protein-protein interactions using AlphaFold2},
  author        = {Bryant, Patrick and Pozzati, Gabriele and Elofsson, Arne},
  journal       = {Nature communications},
  volume        = {13},
  number        = {1},
  pages         = {1265},
  year          = {2022},
  publisher     = {Nature Publishing Group UK London}
}
@inproceedings{guo2016convolutional,
  title         = {Convolutional neural networks for steady flow approximation},
  author        = {Guo, Xiaoxiao and Li, Wei and Iorio, Francesco},
  booktitle     = {Proceedings of the 22nd ACM SIGKDD international conference on knowledge discovery and data mining},
  pages         = {481--490},
  year          = {2016}
}
@article{zhu2018bayesian,
  title         = {Bayesian deep convolutional encoder--decoder networks for surrogate modeling and uncertainty quantification},
  author        = {Zhu, Yinhao and Zabaras, Nicholas},
  journal       = {Journal of Computational Physics},
  volume        = {366},
  pages         = {415--447},
  year          = {2018},
  publisher     = {Elsevier}
}
@article{adler2017solving,
  title         = {Solving ill-posed inverse problems using iterative deep neural networks},
  author        = {Adler, Jonas and {\"O}ktem, Ozan},
  journal       = {Inverse Problems},
  volume        = {33},
  number        = {12},
  pages         = {124007},
  year          = {2017},
  publisher     = {IOP Publishing}
}
@book{fdm,
  title         = {Finite difference methods in heat transfer},
  author        = {{\"O}zi{\c{s}}ik, M Necati and Orlande, Helcio RB and Cola{\c{c}}o, Marcelo J and Cotta, Renato M},
  year          = {2017},
  publisher     = {CRC press}
}
@book{fem,
  title         = {The finite element method: its basis and fundamentals},
  author        = {Zienkiewicz, Olek C and Taylor, Robert L and Zhu, Jian Z},
  year          = {2005},
  publisher     = {Elsevier}
}
@article{fvm,
  title         = {Finite volume methods},
  author        = {Eymard, Robert and Gallou{\"e}t, Thierry and Herbin, Rapha{\`e}le},
  journal       = {Handbook of numerical analysis},
  volume        = {7},
  pages         = {713--1018},
  year          = {2000},
  publisher     = {Elsevier}
}
@article{meshfree,
  title         = {Meshfree methods: a comprehensive review of applications},
  author        = {Garg, Sahil and Pant, Mohit},
  journal       = {International Journal of Computational Methods},
  volume        = {15},
  number        = {04},
  pages         = {1830001},
  year          = {2018},
  publisher     = {World Scientific}
}
@article{spectral,
  title         = {Using spectral method as an approximation for solving hyperbolic PDEs},
  author        = {Pedram, Pouria and Mirzaei, Mahdi and Gousheh, Siamak S},
  journal       = {Computer Physics Communications},
  volume        = {176},
  number        = {9-10},
  pages         = {581--588},
  year          = {2007},
  publisher     = {Elsevier}
}
@book{comsol,
  title         = {Multiphysics modeling using COMSOL{\textregistered}: a first principles approach},
  author        = {Pryor, Roger W},
  year          = {2009},
  publisher     = {Jones \& Bartlett Publishers}
}
@article{fluent,
  title         = {Numerical simulation of the consequences of liquefied ammonia instantaneous release using FLUENT software},
  author        = {Galeev, AD and Starovoytova, EV and Ponikarov, SI},
  journal       = {Process safety and environmental protection},
  volume        = {91},
  number        = {3},
  pages         = {191--201},
  year          = {2013},
  publisher     = {Elsevier}
}
@article{jin2021nsfnets,
  title         = {NSFnets (Navier-Stokes flow nets): Physics-informed neural networks for the incompressible Navier-Stokes equations},
  author        = {Jin, Xiaowei and Cai, Shengze and Li, Hui and Karniadakis, George Em},
  journal       = {Journal of Computational Physics},
  volume        = {426},
  pages         = {109951},
  year          = {2021},
  publisher     = {Elsevier}
}
@article{cai2021physics,
  title         = {Physics-informed neural networks (PINNs) for fluid mechanics: A review},
  author        = {Cai, Shengze and Mao, Zhiping and Wang, Zhicheng and Yin, Minglang and Karniadakis, George Em},
  journal       = {Acta Mechanica Sinica},
  volume        = {37},
  number        = {12},
  pages         = {1727--1738},
  year          = {2021},
  publisher     = {Springer}
}
@article{xuedinge1,
  title         = {Physics-informed neural network for optical fiber parameter estimation from the nonlinear Schr{\"o}dinger equation},
  author        = {Jiang, Xiaotian and Wang, Danshi and Chen, Xue and Zhang, Min},
  journal       = {Journal of Lightwave Technology},
  volume        = {40},
  number        = {21},
  pages         = {7095--7105},
  year          = {2022},
  publisher     = {IEEE}
}
@article{xuedinge2,
  title         = {Mix-training physics-informed neural networks for the rogue waves of nonlinear Schr{\"o}dinger equation},
  author        = {Li, Jiaheng and Li, Biao},
  journal       = {Chaos, Solitons \& Fractals},
  volume        = {164},
  pages         = {112712},
  year          = {2022},
  publisher     = {Elsevier}
}
@article{lim2022maxwellnet,
  title         = {MaxwellNet: Physics-driven deep neural network training based on Maxwell's equations},
  author        = {Lim, Joowon and Psaltis, Demetri},
  journal       = {Apl Photonics},
  volume        = {7},
  number        = {1},
  year          = {2022},
  publisher     = {AIP Publishing}
}
@article{fang2021high,
  title         = {A high-efficient hybrid physics-informed neural networks based on convolutional neural network},
  author        = {Fang, Zhiwei},
  journal       = {IEEE Transactions on Neural Networks and Learning Systems},
  volume        = {33},
  number        = {10},
  pages         = {5514--5526},
  year          = {2021},
  publisher     = {IEEE}
}
@article{ren2022phycrnet,
  title         = {PhyCRNet: Physics-informed convolutional-recurrent network for solving spatiotemporal PDEs},
  author        = {Ren, Pu and Rao, Chengping and Liu, Yang and Wang, Jian-Xun and Sun, Hao},
  journal       = {Computer Methods in Applied Mechanics and Engineering},
  volume        = {389},
  pages         = {114399},
  year          = {2022},
  publisher     = {Elsevier}
}
@inproceedings{afno,
  title         = {Efficient Token Mixing for Transformers via Adaptive Fourier Neural Operators},
  author        = {Guibas, John and Mardani, Morteza and Li, Zongyi and Tao, Andrew and Anandkumar, Anima and Catanzaro, Bryan},
  booktitle     = {International Conference on Learning Representations},
  year          = {2021}
}
@misc{transformerexplain,
  title         = {The Illustrated Transformer},
  author        = {Jay Alammar},
  url           = {https://jalammar.github.io/illustrated-transformer/},
  year          = {2018}
}
@article{schwaller19olecularxformer,
  author        = {Schwaller, Philippe and Laino, Teodoro and Gaudin, Th\'{e}ophile and Bolgar, Peter and Hunter, Christopher A. and Bekas, Costas and Lee, Alpha A.},
  title         = {Molecular Transformer: A Model for Uncertainty-Calibrated Chemical Reaction Prediction},
  journal       = {ACS Central Science},
  volume        = {5},
  number        = {9},
  pages         = {1572--1583},
  year          = {2019},
  doi           = {10.1021/acscentsci.9b00576},
  url           = {https://doi.org/10.1021/acscentsci.9b00576}
}
@article{rivese21biological,
  author        = {Rives, Alexander and Meier, Joshua and Sercu, Tom and Goyal, Siddharth and Lin, Zeming and Liu, Jason and Guo, Demi and Ott, Myle and Zitnick, C. Lawrence and Ma, Jerry and Fergus, Rob},
  title         = {Biological structure and function emerge from scaling unsupervised learning to 250 million protein sequences},
  volume        = {118},
  number        = {15},
  elocation-id  = {e2016239118},
  year          = {2021},
  doi           = {10.1073/pnas.2016239118},
  publisher     = {National Academy of Sciences},
  issn          = {0027-8424},
  url           = {https://www.pnas.org/content/118/15/e2016239118},
  journal       = {Proceedings of the National Academy of Sciences}
}
@inproceedings{ainslie2020etc,
  address       = {Online},
  author        = {Ainslie, Joshua  and Ontanon, Santiago  and Alberti, Chris  and Cvicek, Vaclav  and Fisher, Zachary  and Pham, Philip  and Ravula, Anirudh  and Sanghai, Sumit  and Wang, Qifan  and Yang, Li},
  booktitle     = {Proceedings of EMNLP},
  doi           = {10.18653/v1/2020.emnlp-main.19},
  pages         = {268--284},
  title         = {{ETC}: Encoding Long and Structured Inputs in Transformers},
  url           = {https://www.aclweb.org/anthology/2020.emnlp-main.19},
  year          = {2020}
}
@inproceedings{alrfou2018characterlevel,
  author        = {Rami Al{-}Rfou and Dokook Choe and Noah Constant and Mandy Guo and Llion Jones},
  bibsource     = {dblp computer science bibliography, https://dblp.org},
  biburl        = {https://dblp.org/rec/conf/aaai/Al-RfouCCGJ19.bib},
  booktitle     = {Proceedings of AAAI},
  doi           = {10.1609/aaai.v33i01.33013159},
  pages         = {3159--3166},
  timestamp     = {Thu, 30 Apr 2020 01:00:00 +0200},
  title         = {Character-Level Language Modeling with Deeper Self-Attention},
  url           = {https://doi.org/10.1609/aaai.v33i01.33013159},
  year          = {2019}
}
@misc{arnab2021vivit,
  archiveprefix = {arXiv},
  author        = {Anurag Arnab and Mostafa Dehghani and Georg Heigold and Chen Sun and Mario Lu\v{c}i\'{c} and Cordelia Schmid},
  eprint        = {2103.15691},
  primaryclass  = {cs.CV},
  title         = {ViViT: A Video Vision Transformer},
  year          = {2021}
}
@inproceedings{baevski2019adaptive,
  author        = {Alexei Baevski and Michael Auli},
  bibsource     = {dblp computer science bibliography, https://dblp.org},
  biburl        = {https://dblp.org/rec/conf/iclr/BaevskiA19.bib},
  booktitle     = {Proceedings of ICLR},
  timestamp     = {Thu, 25 Jul 2019 01:00:00 +0200},
  title         = {Adaptive Input Representations for Neural Language Modeling},
  url           = {https://openreview.net/forum?id=ByxZX20qFQ},
  year          = {2019}
}
@misc{beltagy2020longformer,
  archiveprefix = {arXiv},
  author        = {Iz Beltagy and Matthew E. Peters and Arman Cohan},
  eprint        = {2004.05150},
  primaryclass  = {cs.CL},
  title         = {Longformer: The Long-Document Transformer},
  year          = {2020}
}
@inproceedings{bhoj20lowrankbottleneck,
  author        = {Srinadh Bhojanapalli and Chulhee Yun and Ankit Singh Rawat and Sashank J. Reddi and Sanjiv Kumar},
  bibsource     = {dblp computer science bibliography, https://dblp.org},
  biburl        = {https://dblp.org/rec/conf/icml/BhojanapalliYRR20.bib},
  booktitle     = {Proceedings of ICML},
  pages         = {864--873},
  timestamp     = {Xiong, Yunyang and Zeng, Zhanpeng and Chakraborty, Rudrasis and Tan, Mingxing and Fung, Glenn and Li, Yin and Singh, Vikas},
  year          = {2021}
}
@inproceedings{chen20compressedlowrank,
  author        = {Ziye Chen and Mingming Gong and Lingjuan Ge and Bo Du},
  title         = {Compressed Self-Attention for Deep Metric Learning with Low-Rank Approximation},
  booktitle     = {Proceedings of IJCAI},
  pages         = {2058--2064},
  year          = {2020},
  url           = {https://doi.org/10.24963/ijcai.2020/285},
  doi           = {10.24963/ijcai.2020/285},
  timestamp     = {Mon, 20 Jul 2020 12:38:52 +0200},
  biburl        = {https://dblp.org/rec/conf/ijcai/ChenGGD20.bib},
  bibsource     = {dblp computer science bibliography, https://dblp.org}
}
@inproceedings{deshpande20guidingattention,
  address       = {Online},
  author        = {Deshpande, Ameet  and Narasimhan, Karthik},
  booktitle     = {Findings of the Association for Computational Linguistics: EMNLP 2020},
  doi           = {10.18653/v1/2020.findings-emnlp.419},
  pages         = {4676--4686},
  title         = {Guiding Attention for Self-Supervised Learning with Transformers},
  url           = {https://www.aclweb.org/anthology/2020.findings-emnlp.419},
  year          = {2020}
}
@inproceedings{devlin2019bert,
  address       = {Minneapolis, Minnesota},
  author        = {Devlin, Jacob  and Chang, Ming-Wei  and Lee, Kenton  and Toutanova, Kristina},
  booktitle     = {Proceedings of HLT-NAACL},
  doi           = {10.18653/v1/N19-1423},
  pages         = {4171--4186},
  title         = {{BERT}: Pre-training of Deep Bidirectional Transformers for Language Understanding},
  url           = {https://www.aclweb.org/anthology/N19-1423},
  year          = {2019}
}
@inproceedings{dong18speechxformer,
  author        = {Linhao Dong and Shuang Xu and Bo Xu},
  bibsource     = {dblp computer science bibliography, https://dblp.org},
  biburl        = {https://dblp.org/rec/conf/icassp/DongXX18.bib},
  booktitle     = {Proceedings of ICASSP},
  doi           = {10.1109/ICASSP.2018.8462506},
  pages         = {5884--5888},
  timestamp     = {Tue, 25 Jun 2019 01:00:00 +0200},
  title         = {Speech-Transformer: {A} No-Recurrence Sequence-to-Sequence Model for Speech Recognition},
  url           = {https://doi.org/10.1109/ICASSP.2018.8462506},
  year          = {2018}
}
@misc{dosovitskiy2020vit,
  archiveprefix = {arXiv},
  author        = {Alexey Dosovitskiy and Lucas Beyer and Alexander Kolesnikov and Dirk Weissenborn and Xiaohua Zhai and Thomas Unterthiner and Mostafa Dehghani and Matthias Minderer and Georg Heigold and Sylvain Gelly and Jakob Uszkoreit and Neil Houlsby},
  eprint        = {2010.11929},
  primaryclass  = {cs.CV},
  title         = {An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale},
  year          = {2020}
}
@article{fedus2021switch,
  author        = {William Fedus and Barret Zoph and Noam Shazeer},
  title         = {Switch Transformers: Scaling to Trillion Parameter Models with Simple and Efficient Sparsity},
  journal       = {CoRR},
  volume        = {abs/2101.03961},
  year          = {2021},
  archiveprefix = {arXiv},
  eprint        = {2101.03961},
  timestamp     = {Thu, 21 Jan 2021 14:42:30 +0100},
  biburl        = {https://dblp.org/rec/journals/corr/abs-2101-03961.bib},
  bibsource     = {dblp computer science bibliography, https://dblp.org}
}
@inproceedings{gehring2017convolutional,
  author        = {Jonas Gehring and Michael Auli and David Grangier and Denis Yarats and Yann N. Dauphin},
  bibsource     = {dblp computer science bibliography, https://dblp.org},
  biburl        = {https://dblp.org/rec/conf/icml/GehringAGYD17.bib},
  booktitle     = {Proceedings of ICML},
  pages         = {1243--1252},
  timestamp     = {Wed, 03 Apr 2019 01:00:00 +0200},
  title         = {Convolutional Sequence to Sequence Learning},
  year          = {2017}
}
@inproceedings{gu19capsule,
  author        = {Shuhao Gu and Yang Feng},
  bibsource     = {dblp computer science bibliography, https://dblp.org},
  biburl        = {https://dblp.org/rec/conf/nlpcc/GuF19.bib},
  booktitle     = {Proceedings of NLPCC},
  doi           = {10.1007/978-3-030-32233-5\_25},
  pages         = {314--326},
  timestamp     = {Fri, 06 Nov 2020 12:29:14 +0100},
  title         = {Improving Multi-head Attention with Capsule Networks},
  url           = {https://doi.org/10.1007/978-3-030-32233-5\_25},
  year          = {2019}
}
@inproceedings{gulati20conformer,
  author        = {Anmol Gulati and James Qin and Chung{-}Cheng Chiu and Niki Parmar and Yu Zhang and Jiahui Yu and Wei Han and Shibo Wang and Zhengdong Zhang and Yonghui Wu and Ruoming Pang},
  bibsource     = {dblp computer science bibliography, https://dblp.org},
  biburl        = {https://dblp.org/rec/conf/interspeech/GulatiQCPZYHWZW20.bib},
  booktitle     = {Proceedings of Interspeech},
  doi           = {10.21437/Interspeech.2020-3015},
  pages         = {5036--5040},
  timestamp     = {Fri, 29 Jan 2021 17:40:18 +0100},
  title         = {Conformer: Convolution-augmented Transformer for Speech Recognition},
  url           = {https://doi.org/10.21437/Interspeech.2020-3015},
  year          = {2020}
}
@inproceedings{guo19gaussian,
  author        = {Maosheng Guo and Yu Zhang and Ting Liu},
  bibsource     = {dblp computer science bibliography, https://dblp.org},
  biburl        = {https://dblp.org/rec/conf/aaai/GuoZL19.bib},
  booktitle     = {Proceedings of AAAI},
  doi           = {10.1609/aaai.v33i01.33016489},
  pages         = {6489--6496},
  timestamp     = {Wed, 25 Sep 2019 01:00:00 +0200},
  title         = {Gaussian Transformer: {A} Lightweight Approach for Natural Language Inference},
  url           = {https://doi.org/10.1609/aaai.v33i01.33016489},
  year          = {2019}
}
@article{guo19lowrank,
  author        = {Guo, Qipeng and Qiu, Xipeng and Xue, Xiangyang and Zhang, Zheng},
  doi           = {10.1109/TASLP.2019.2944078},
  issn          = {2329-9290},
  issue_date    = {Dec. 2019},
  journal       = {IEEE/ACM Trans. Audio, Speech and Lang. Proc.},
  number        = {12},
  numpages      = {10},
  pages         = {2213â€“2222},
  title         = {Low-Rank and Locality Constrained Self-Attention for Sequence Modeling},
  url           = {https://doi.org/10.1109/TASLP.2019.2944078},
  volume        = {27},
  year          = {2019}
}
@inproceedings{guo2019multiscale,
  author        = {Qipeng Guo and Xipeng Qiu and Pengfei Liu and Xiangyang Xue and Zheng Zhang},
  bibsource     = {dblp computer science bibliography, https://dblp.org},
  biburl        = {https://dblp.org/rec/conf/aaai/GuoQLXZ20.bib},
  booktitle     = {Proceedings of AAAI},
  pages         = {7847--7854},
  timestamp     = {Mon, 23 Nov 2020 00:00:00 +0100},
  title         = {Multi-Scale Self-Attention for Text Classification},
  url           = {https://aaai.org/ojs/index.php/AAAI/article/view/6290},
  year          = {2020}
}
@inproceedings{guo2019startransformer,
  author        = {Guo, Qipeng  and Qiu, Xipeng  and Liu, Pengfei  and Shao, Yunfan  and Xue, Xiangyang  and Zhang, Zheng},
  booktitle     = {Proceedings of HLT-NAACL},
  pages         = {1315--1325},
  title         = {Star-Transformer},
  url           = {https://www.aclweb.org/anthology/N19-1133},
  year          = {2019}
}
@misc{han2021tnt,
  archiveprefix = {arXiv},
  author        = {Kai Han and An Xiao and Enhua Wu and Jianyuan Guo and Chunjing Xu and Yunhe Wang},
  eprint        = {2103.00112},
  primaryclass  = {cs.CV},
  title         = {Transformer in Transformer},
  year          = {2021}
}
@misc{he2020realformer,
  archiveprefix = {arXiv},
  author        = {Ruining He and Anirudh Ravula and Bhargav Kanagal and Joshua Ainslie},
  eprint        = {2012.11747},
  primaryclass  = {cs.LG},
  title         = {RealFormer: Transformer Likes Residual Attention},
  year          = {2020}
}
@inproceedings{Hu_2020_CVPR,
  author        = {Ronghang Hu and Amanpreet Singh and Trevor Darrell and Marcus Rohrbach},
  bibsource     = {dblp computer science bibliography, https://dblp.org},
  biburl        = {https://dblp.org/rec/conf/cvpr/HuSDR20.bib},
  booktitle     = {2020 {IEEE/CVF} Conference on Computer Vision and Pattern Recognition, {CVPR} 2020, Seattle, WA, USA, June 13-19, 2020},
  doi           = {10.1109/CVPR42600.2020.01001},
  pages         = {9989--9999},
  timestamp     = {Tue, 11 Aug 2020 01:00:00 +0200},
  title         = {Iterative Answer Prediction With Pointer-Augmented Multimodal Transformers for TextVQA},
  url           = {https://doi.org/10.1109/CVPR42600.2020.01001},
  year          = {2020}
}
@inproceedings{huang2018music,
  author        = {Cheng-Zhi Anna Huang and Ashish Vaswani and Jakob Uszkoreit and Ian Simon and Curtis Hawthorne and Noam Shazeer and Andrew M. Dai and Matthew D. Hoffman and Monica Dinculescu and Douglas Eck},
  booktitle     = {Proceedings of ICLR},
  title         = {Music Transformer},
  url           = {https://openreview.net/forum?id=rJe4ShAcF7},
  year          = {2019}
}
@inproceedings{IrieZSN19LM,
  author        = {Kazuki Irie and Albert Zeyer and Ralf Schl{\"{u}}ter and Hermann Ney},
  bibsource     = {dblp computer science bibliography, https://dblp.org},
  biburl        = {https://dblp.org/rec/conf/interspeech/IrieZSN19.bib},
  booktitle     = {Proceedings of Interspeech},
  doi           = {10.21437/Interspeech.2019-2225},
  pages         = {3905--3909},
  timestamp     = {Fri, 29 Jan 2021 17:41:10 +0100},
  title         = {Language Modeling with Deep Transformers},
  url           = {https://doi.org/10.21437/Interspeech.2019-2225},
  year          = {2019}
}
@inproceedings{islam20cnnpos,
  author        = {Md. Amirul Islam and Sen Jia and Neil D. B. Bruce},
  bibsource     = {dblp computer science bibliography, https://dblp.org},
  biburl        = {https://dblp.org/rec/conf/iclr/IslamJB20.bib},
  booktitle     = {Proceedings of ICLR},
  timestamp     = {Thu, 07 May 2020 01:00:00 +0200},
  title         = {How much Position Information Do Convolutional Neural Networks Encode?},
  url           = {https://openreview.net/forum?id=rJeB36NKvB},
  year          = {2020}
}
@inproceedings{katharopoulos2020linearxformer,
  author        = {Angelos Katharopoulos and Apoorv Vyas and Nikolaos Pappas and Fran{\c{c}}ois Fleuret},
  bibsource     = {dblp computer science bibliography, https://dblp.org},
  biburl        = {https://dblp.org/rec/conf/icml/KatharopoulosV020.bib},
  booktitle     = {Proceedings of ICML},
  pages         = {5156--5165},
  timestamp     = {Tue, 15 Dec 2020 00:00:00 +0100},
  title         = {Transformers are RNNs: Fast Autoregressive Transformers with Linear Attention},
  url           = {http://proceedings.mlr.press/v119/katharopoulos20a.html},
  year          = {2020}
}
@misc{ke2020tupe,
  archiveprefix = {arXiv},
  author        = {Guolin Ke and Di He and Tie-Yan Liu},
  eprint        = {2006.15595},
  primaryclass  = {cs.CL},
  title         = {Rethinking Positional Encoding in Language Pre-training},
  year          = {2020}
}
@inproceedings{kitaev2020reformer,
  author        = {Nikita Kitaev and Lukasz Kaiser and Anselm Levskaya},
  bibsource     = {dblp computer science bibliography, https://dblp.org},
  biburl        = {https://dblp.org/rec/conf/iclr/KitaevKL20.bib},
  booktitle     = {Proceedings of ICLR},
  timestamp     = {Thu, 07 May 2020 01:00:00 +0200},
  title         = {Reformer: The Efficient Transformer},
  url           = {https://openreview.net/forum?id=rkgNKkHtvB},
  year          = {2020}
}
@inproceedings{lample2019large,
  author        = {Guillaume Lample and Alexandre Sablayrolles and Marc'Aurelio Ranzato and Ludovic Denoyer and Herv{\'{e}} J{\'{e}}gou},
  bibsource     = {dblp computer science bibliography, https://dblp.org},
  biburl        = {https://dblp.org/rec/conf/nips/LampleSRDJ19.bib},
  booktitle     = {Proceedings of NeurIPS},
  pages         = {8546--8557},
  timestamp     = {Thu, 21 Jan 2021 00:00:00 +0100},
  title         = {Large Memory Layers with Product Keys},
  url           = {https://proceedings.neurips.cc/paper/2019/hash/9d8df73a3cfbf3c5b47bc9b50f214aff-Abstract.html},
  year          = {2019}
}
@inproceedings{lee2019set,
  author        = {Juho Lee and Yoonho Lee and Jungtaek Kim and Adam R. Kosiorek and Seungjin Choi and Yee Whye Teh},
  bibsource     = {dblp computer science bibliography, https://dblp.org},
  biburl        = {https://dblp.org/rec/conf/icml/LeeLKKCT19.bib},
  booktitle     = {Proceedings of ICML},
  pages         = {3744--3753},
  timestamp     = {Thu, 14 Jan 2021 00:00:00 +0100},
  title         = {Set Transformer: {A} Framework for Attention-based Permutation-Invariant Neural Networks},
  url           = {http://proceedings.mlr.press/v97/lee19d.html},
  year          = {2019}
}
@article{lepikhin20gshard,
  archiveprefix = {arXiv},
  author        = {Dmitry Lepikhin and HyoukJoong Lee and Yuanzhong Xu and Dehao Chen and Orhan Firat and Yanping Huang and Maxim Krikun and Noam Shazeer and Zhifeng Chen},
  bibsource     = {dblp computer science bibliography, https://dblp.org},
  biburl        = {https://dblp.org/rec/journals/corr/abs-2006-16668.bib},
  eprint        = {2006.16668},
  journal       = {CoRR},
  timestamp     = {Thu, 02 Jul 2020 14:42:48 +0200},
  title         = {GShard: Scaling Giant Models with Conditional Computation and Automatic Sharding},
  volume        = {abs/2006.16668},
  year          = {2020}
}
@inproceedings{li-etal-2019-multiheadrout,
  author        = {Li, Jian  and Yang, Baosong  and Dou, Zi-Yi  and Wang, Xing  and Lyu, Michael R.  and Tu, Zhaopeng},
  booktitle     = {Proceedings of HLT-NAACL},
  doi           = {10.18653/v1/N19-1359},
  pages         = {3566--3575},
  title         = {Information Aggregation for Multi-Head Attention with Routing-by-Agreement},
  url           = {https://www.aclweb.org/anthology/N19-1359},
  year          = {2019}
}
@inproceedings{li2020sac,
  author        = {Xiaoya Li and Yuxian Meng and Mingxin Zhou and Qinghong Han and Fei Wu and Jiwei Li},
  bibsource     = {dblp computer science bibliography, https://dblp.org},
  biburl        = {https://dblp.org/rec/conf/nips/LiMZHWL20.bib},
  booktitle     = {Proceedings of NeurIPS},
  timestamp     = {Tue, 19 Jan 2021 00:00:00 +0100},
  title         = {{SAC:} Accelerating and Structuring Self-Attention via Sparse Adaptive Connection},
  url           = {https://proceedings.neurips.cc/paper/2020/hash/c5c1bda1194f9423d744e0ef67df94ee-Abstract.html},
  year          = {2020}
}
@inproceedings{liu2018generating,
  author        = {Peter J. Liu and Mohammad Saleh and Etienne Pot and Ben Goodrich and Ryan Sepassi and Lukasz Kaiser and Noam Shazeer},
  bibsource     = {dblp computer science bibliography, https://dblp.org},
  biburl        = {https://dblp.org/rec/conf/iclr/LiuSPGSKS18.bib},
  booktitle     = {Proceedings of ICLR},
  timestamp     = {Thu, 25 Jul 2019 01:00:00 +0200},
  title         = {Generating Wikipedia by Summarizing Long Sequences},
  url           = {https://openreview.net/forum?id=Hyg0vbWC-},
  year          = {2018}
}
@inproceedings{liu2020floater,
  author        = {Xuanqing Liu and Hsiang{-}Fu Yu and Inderjit S. Dhillon and Cho{-}Jui Hsieh},
  bibsource     = {dblp computer science bibliography, https://dblp.org},
  biburl        = {https://dblp.org/rec/conf/icml/LiuYDH20.bib},
  booktitle     = {Proceedings of ICML},
  pages         = {6327--6335},
  timestamp     = {Tue, 15 Dec 2020 00:00:00 +0100},
  title         = {Learning to Encode Position for Transformer with Continuous Dynamical Model},
  url           = {http://proceedings.mlr.press/v119/liu20n.html},
  year          = {2020}
}
@misc{liu2021swin,
  archiveprefix = {arXiv},
  author        = {Ze Liu and Yutong Lin and Yue Cao and Han Hu and Yixuan Wei and Zheng Zhang and Stephen Lin and Baining Guo},
  eprint        = {2103.14030},
  primaryclass  = {cs.CV},
  title         = {Swin Transformer: Hierarchical Vision Transformer using Shifted Windows},
  year          = {2021}
}
@misc{lu19macaron,
  title         = {Understanding and Improving Transformer From a Multi-Particle Dynamic System Point of View},
  author        = {Yiping Lu and Zhuohan Li and Di He and Zhiqing Sun and Bin Dong and Tao Qin and Liwei Wang and Tie-Yan Liu},
  year          = {2020},
  url           = {https://openreview.net/forum?id=SJl1o2NFwS}
}
@misc{mehta2020delight,
  archiveprefix = {arXiv},
  author        = {Sachin Mehta and Marjan Ghazvininejad and Srinivasan Iyer and Luke Zettlemoyer and Hannaneh Hajishirzi},
  eprint        = {2008.00623},
  primaryclass  = {cs.LG},
  title         = {DeLighT: Very Deep and Light-weight Transformer},
  year          = {2020}
}
@inproceedings{miculicich-etal-2018-document,
  address       = {Brussels, Belgium},
  author        = {Miculicich, Lesly  and Ram, Dhananjay  and Pappas, Nikolaos  and Henderson, James},
  booktitle     = {Proceedings of EMNLP},
  doi           = {10.18653/v1/D18-1325},
  pages         = {2947--2954},
  title         = {Document-Level Neural Machine Translation with Hierarchical Attention Networks},
  url           = {https://www.aclweb.org/anthology/D18-1325},
  year          = {2018}
}
@inproceedings{parmar2018imagexformer,
  author        = {Niki Parmar and Ashish Vaswani and Jakob Uszkoreit and Lukasz Kaiser and Noam Shazeer and Alexander Ku and Dustin Tran},
  bibsource     = {dblp computer science bibliography, https://dblp.org},
  biburl        = {https://dblp.org/rec/conf/icml/ParmarVUKSKT18.bib},
  booktitle     = {Proceedings of ICML},
  pages         = {4052--4061},
  timestamp     = {Wed, 03 Apr 2019 01:00:00 +0200},
  title         = {Image Transformer},
  url           = {http://proceedings.mlr.press/v80/parmar18a.html},
  year          = {2018}
}
@inproceedings{peng2021random,
  author        = {Hao Peng and Nikolaos Pappas and Dani Yogatama and Roy Schwartz and Noah Smith and Lingpeng Kong},
  booktitle     = {Proceedings of ICLR},
  title         = {Random Feature Attention},
  url           = {https://openreview.net/forum?id=QtTKTdVrFBB},
  year          = {2021}
}
@inproceedings{rae2019compressive,
  author        = {Jack W. Rae and Anna Potapenko and Siddhant M. Jayakumar and Chloe Hillier and Timothy P. Lillicrap},
  bibsource     = {dblp computer science bibliography, https://dblp.org},
  biburl        = {https://dblp.org/rec/conf/iclr/RaePJHL20.bib},
  booktitle     = {Proceedings of ICLR},
  timestamp     = {Thu, 07 May 2020 01:00:00 +0200},
  title         = {Compressive Transformers for Long-Range Sequence Modelling},
  url           = {https://openreview.net/forum?id=SylKikSYDH},
  year          = {2020}
}
@misc{raffel2020t5,
  archiveprefix = {arXiv},
  author        = {Colin Raffel and Noam Shazeer and Adam Roberts and Katherine Lee and Sharan Narang and Michael Matena and Yanqi Zhou and Wei Li and Peter J. Liu},
  eprint        = {1910.10683},
  primaryclass  = {cs.LG},
  title         = {Exploring the Limits of Transfer Learning with a Unified Text-to-Text Transformer},
  year          = {2020}
}
@inproceedings{rahmi07random,
  author        = {Ali Rahimi and Benjamin Recht},
  bibsource     = {dblp computer science bibliography, https://dblp.org},
  biburl        = {https://dblp.org/rec/conf/nips/RahimiR07.bib},
  booktitle     = {Proceedings of NeurIPS},
  pages         = {1177--1184},
  timestamp     = {Thu, 21 Jan 2021 00:00:00 +0100},
  title         = {Random Features for Large-Scale Kernel Machines},
  url           = {https://proceedings.neurips.cc/paper/2007/hash/013a006f03dbc5392effeb8f18fda755-Abstract.html},
  year          = {2007}
}
@misc{ramesh2021dalle,
  archiveprefix = {arXiv},
  author        = {Aditya Ramesh and Mikhail Pavlov and Gabriel Goh and Scott Gray and Chelsea Voss and Alec Radford and Mark Chen and Ilya Sutskever},
  eprint        = {2102.12092},
  primaryclass  = {cs.CV},
  title         = {Zero-Shot Text-to-Image Generation},
  year          = {2021}
}
@misc{roy2020efficient,
  archiveprefix = {arXiv},
  author        = {Aurko Roy and Mohammad Saffar and Ashish Vaswani and David Grangier},
  eprint        = {2003.05997},
  primaryclass  = {cs.LG},
  title         = {Efficient Content-Based Sparse Attention with Routing Transformers},
  year          = {2020}
}
@inproceedings{ofir20sandwichxformer,
  address       = {Online},
  author        = {Press, Ofir  and Smith, Noah A.  and Levy, Omer},
  booktitle     = {Proceedings of ACL},
  doi           = {10.18653/v1/2020.acl-main.270},
  pages         = {2996--3005},
  title         = {Improving Transformer Models by Reordering their Sublayers},
  url           = {https://www.aclweb.org/anthology/2020.acl-main.270},
  year          = {2020}
}
@article{schlag21fastweight,
  archiveprefix = {arXiv},
  author        = {Imanol Schlag and Kazuki Irie and J{\"{u}}rgen Schmidhuber},
  bibsource     = {dblp computer science bibliography, https://dblp.org},
  biburl        = {https://dblp.org/rec/journals/corr/abs-2102-11174.bib},
  eprint        = {2102.11174},
  journal       = {CoRR},
  timestamp     = {Wed, 24 Feb 2021 15:42:45 +0100},
  title         = {Linear Transformers Are Secretly Fast Weight Memory Systems},
  volume        = {abs/2102.11174},
  year          = {2021}
}
@inproceedings{shaw2018relative,
  address       = {New Orleans, Louisiana},
  author        = {Shaw, Peter  and Uszkoreit, Jakob  and Vaswani, Ashish},
  booktitle     = {Proceedings of HLT-NAACL},
  doi           = {10.18653/v1/N18-2074},
  pages         = {464--468},
  title         = {Self-Attention with Relative Position Representations},
  url           = {https://www.aclweb.org/anthology/N18-2074},
  year          = {2018}
}
@inproceedings{shen2020powernorm,
  author        = {Sheng Shen and Zhewei Yao and Amir Gholami and Michael W. Mahoney and Kurt Keutzer},
  bibsource     = {dblp computer science bibliography, https://dblp.org},
  biburl        = {https://dblp.org/rec/conf/icml/ShenYGMK20.bib},
  booktitle     = {Proceedings of ICML},
  pages         = {8741--8751},
  timestamp     = {Tue, 15 Dec 2020 00:00:00 +0100},
  title         = {PowerNorm: Rethinking Batch Normalization in Transformers},
  url           = {http://proceedings.mlr.press/v119/shen20e.html},
  year          = {2020}
}
@inproceedings{su20vlbert,
  author        = {Weijie Su and Xizhou Zhu and Yue Cao and Bin Li and Lewei Lu and Furu Wei and Jifeng Dai},
  bibsource     = {dblp computer science bibliography, https://dblp.org},
  biburl        = {https://dblp.org/rec/conf/iclr/SuZCLLWD20.bib},
  booktitle     = {Proceedings of ICLR},
  timestamp     = {Thu, 07 May 2020 01:00:00 +0200},
  title         = {{VL-BERT:} Pre-training of Generic Visual-Linguistic Representations},
  url           = {https://openreview.net/forum?id=SygXPaEYvH},
  year          = {2020}
}
@inproceedings{Sukhbaatar19adaptivespan,
  address       = {Florence, Italy},
  author        = {Sukhbaatar, Sainbayar  and Grave, Edouard  and Bojanowski, Piotr  and Joulin, Armand},
  booktitle     = {Proceedings of ACL},
  doi           = {10.18653/v1/P19-1032},
  pages         = {331--335},
  title         = {Adaptive Attention Span in Transformers},
  url           = {https://www.aclweb.org/anthology/P19-1032},
  year          = {2019}
}
@misc{sukhbaatar2019augmenting,
  archiveprefix = {arXiv},
  author        = {Sainbayar Sukhbaatar and Edouard Grave and Guillaume Lample and Herve Jegou and Armand Joulin},
  eprint        = {1907.01470},
  primaryclass  = {cs.LG},
  title         = {Augmenting Self-attention with Persistent Memory},
  year          = {2019}
}
@inproceedings{sun19videobert,
  author        = {Chen Sun and Austin Myers and Carl Vondrick and Kevin Murphy and Cordelia Schmid},
  bibsource     = {dblp computer science bibliography, https://dblp.org},
  biburl        = {https://dblp.org/rec/conf/iccv/SunMV0S19.bib},
  booktitle     = {Proceedings of ICCV},
  doi           = {10.1109/ICCV.2019.00756},
  pages         = {7463--7472},
  timestamp     = {Wed, 21 Oct 2020 01:00:00 +0200},
  title         = {VideoBERT: {A} Joint Model for Video and Language Representation Learning},
  url           = {https://doi.org/10.1109/ICCV.2019.00756},
  year          = {2019}
}
@article{synthesizer,
  archiveprefix = {arXiv},
  author        = {Yi Tay and Dara Bahri and Donald Metzler and Da{-}Cheng Juan and Zhe Zhao and Che Zheng},
  bibsource     = {dblp computer science bibliography, https://dblp.org},
  biburl        = {https://dblp.org/rec/journals/corr/abs-2005-00743.bib},
  eprint        = {2005.00743},
  journal       = {CoRR},
  timestamp     = {Fri, 08 May 2020 15:04:04 +0200},
  title         = {Synthesizer: Rethinking Self-Attention in Transformer Models},
  volume        = {abs/2005.00743},
  year          = {2020}
}
@inproceedings{tay2020sparse,
  author        = {Yi Tay and Dara Bahri and Liu Yang and Donald Metzler and Da{-}Cheng Juan},
  bibsource     = {dblp computer science bibliography, https://dblp.org},
  biburl        = {https://dblp.org/rec/conf/icml/TayBYMJ20.bib},
  booktitle     = {Proceedings of ICML},
  pages         = {9438--9447},
  timestamp     = {Tue, 15 Dec 2020 00:00:00 +0100},
  title         = {Sparse Sinkhorn Attention},
  url           = {http://proceedings.mlr.press/v119/tay20a.html},
  year          = {2020}
}
@inproceedings{Chen18transparentxformer,
  address       = {Brussels, Belgium},
  author        = {Bapna, Ankur  and Chen, Mia  and Firat, Orhan  and Cao, Yuan  and Wu, Yonghui},
  booktitle     = {Proceedings of EMNLP},
  doi           = {10.18653/v1/D18-1338},
  pages         = {3028--3033},
  title         = {Training Deeper Neural Machine Translation Models with Transparent Attention},
  url           = {https://www.aclweb.org/anthology/D18-1338},
  year          = {2018}
}
@inproceedings{tsai-etal-2019-dissection,
  address       = {Hong Kong, China},
  author        = {Tsai, Yao-Hung Hubert  and Bai, Shaojie  and Yamada, Makoto  and Morency, Louis-Philippe  and Salakhutdinov, Ruslan},
  booktitle     = {Proceedings of EMNLP-IJCNLP},
  doi           = {10.18653/v1/D19-1443},
  pages         = {4344--4353},
  title         = {Transformer Dissection: An Unified Understanding for Transformer{'}s Attention via the Lens of Kernel},
  url           = {https://www.aclweb.org/anthology/D19-1443},
  year          = {2019}
}
@inproceedings{universalxformer,
  author        = {Mostafa Dehghani and Stephan Gouws and Oriol Vinyals and Jakob Uszkoreit and Lukasz Kaiser},
  bibsource     = {dblp computer science bibliography, https://dblp.org},
  biburl        = {https://dblp.org/rec/conf/iclr/DehghaniGVUK19.bib},
  booktitle     = {Proceedings of ICLR},
  timestamp     = {Thu, 25 Jul 2019 01:00:00 +0200},
  title         = {Universal Transformers},
  url           = {https://openreview.net/forum?id=HyzdRiR9Y7},
  year          = {2019}
}
@inproceedings{vaswani2017attention,
  author        = {Ashish Vaswani and Noam Shazeer and Niki Parmar and Jakob Uszkoreit and Llion Jones and Aidan N. Gomez and Lukasz Kaiser and Illia Polosukhin},
  bibsource     = {dblp computer science bibliography, https://dblp.org},
  biburl        = {https://dblp.org/rec/conf/nips/VaswaniSPUJGKP17.bib},
  booktitle     = {Proceedings of NeurIPS},
  pages         = {5998--6008},
  timestamp     = {Thu, 21 Jan 2021 00:00:00 +0100},
  title         = {Attention is All you Need},
  url           = {https://proceedings.neurips.cc/paper/2017/hash/3f5ee243547dee91fbd053c1c4a845aa-Abstract.html},
  year          = {2017}
}
@misc{vyas2020clusteredattn,
  archiveprefix = {arXiv},
  author        = {Apoorv Vyas and Angelos Katharopoulos and Fran\c{c}ois Fleuret},
  eprint        = {2007.04825},
  primaryclass  = {cs.LG},
  title         = {Fast Transformers with Clustered Attention},
  year          = {2020}
}
@article{wang19rxformer,
  archiveprefix = {arXiv},
  author        = {Zhiwei Wang and Yao Ma and Zitao Liu and Jiliang Tang},
  bibsource     = {dblp computer science bibliography, https://dblp.org},
  biburl        = {https://dblp.org/rec/journals/corr/abs-1907-05572.bib},
  eprint        = {1907.05572},
  journal       = {CoRR},
  timestamp     = {Mon, 08 Feb 2021 14:04:25 +0100},
  title         = {R-Transformer: Recurrent Neural Network Enhanced Transformer},
  volume        = {abs/1907.05572},
  year          = {2019}
}
@inproceedings{wang2020complex,
  author        = {Benyou Wang and Donghao Zhao and Christina Lioma and Qiuchi Li and Peng Zhang and Jakob Grue Simonsen},
  bibsource     = {dblp computer science bibliography, https://dblp.org},
  biburl        = {https://dblp.org/rec/conf/iclr/WangZLLZS20.bib},
  booktitle     = {Proceedings of ICLR},
  timestamp     = {Thu, 07 May 2020 01:00:00 +0200},
  title         = {Encoding word order in complex embeddings},
  url           = {https://openreview.net/forum?id=Hke-WTVtwr},
  year          = {2020}
}
@misc{wang2020linformer,
  archiveprefix = {arXiv},
  author        = {Sinong Wang and Belinda Z. Li and Madian Khabsa and Han Fang and Hao Ma},
  eprint        = {2006.04768},
  primaryclass  = {cs.LG},
  title         = {Linformer: Self-Attention with Linear Complexity},
  year          = {2020}
}
@inproceedings{wang2021peonbert,
  author        = {Benyou Wang and Lifeng Shang and Christina Lioma and Xin Jiang and Hao Yang and Qun Liu and Jakob Grue Simonsen},
  booktitle     = {Proceedings of ICLR},
  title         = {On Position Embeddings in BERT},
  year          = {2021}
}
@misc{wang2021predictive,
  author        = {Yujing Wang and Yaming Yang and Jiangang Bai and Mingliang Zhang and Jing Bai and Jing Yu and Ce Zhang and Yunhai Tong},
  title         = {Predictive Attention Transformer: Improving Transformer with Attention Map Prediction},
  url           = {https://openreview.net/forum?id=YQVjbJPnPc9},
  year          = {2021}
}
@inproceedings{wu2019paylessattention,
  author        = {Felix Wu and Angela Fan and Alexei Baevski and Yann N. Dauphin and Michael Auli},
  bibsource     = {dblp computer science bibliography, https://dblp.org},
  biburl        = {https://dblp.org/rec/conf/iclr/WuFBDA19.bib},
  booktitle     = {Proceedings of ICLR},
  timestamp     = {Thu, 25 Jul 2019 01:00:00 +0200},
  title         = {Pay Less Attention with Lightweight and Dynamic Convolutions},
  url           = {https://openreview.net/forum?id=SkVhlh09tX},
  year          = {2019}
}
@misc{wu2020memformer,
  archiveprefix = {arXiv},
  author        = {Qingyang Wu and Zhenzhong Lan and Jing Gu and Zhou Yu},
  eprint        = {2010.06891},
  primaryclass  = {cs.CL},
  title         = {Memformer: The Memory-Augmented Transformer},
  year          = {2020}
}
@inproceedings{xiong2020layer,
  author        = {Ruibin Xiong and Yunchang Yang and Di He and Kai Zheng and Shuxin Zheng and Chen Xing and Huishuai Zhang and Yanyan Lan and Liwei Wang and Tie{-}Yan Liu},
  bibsource     = {dblp computer science bibliography, https://dblp.org},
  biburl        = {https://dblp.org/rec/conf/icml/XiongYHZZXZLWL20.bib},
  booktitle     = {Proceedings of ICML},
  pages         = {10524--10533},
  timestamp     = {Tue, 15 Dec 2020 00:00:00 +0100},
  title         = {On Layer Normalization in the Transformer Architecture},
  url           = {http://proceedings.mlr.press/v119/xiong20b.html},
  year          = {2020}
}
@article{yan2019tener,
  author        = {Yan, Hang and Deng, Bocao and Li, Xiaonan and Qiu, Xipeng},
  journal       = {arXiv preprint arXiv:1911.04474},
  title         = {{TENER}: Adapting transformer encoder for named entity recognition},
  year          = {2019}
}
@inproceedings{yang18localness,
  address       = {Brussels, Belgium},
  author        = {Yang, Baosong  and Tu, Zhaopeng  and Wong, Derek F.  and Meng, Fandong  and Chao, Lidia S.  and Zhang, Tong},
  booktitle     = {Proceedings of EMNLP},
  doi           = {10.18653/v1/D18-1475},
  pages         = {4449--4458},
  title         = {Modeling Localness for Self-Attention Networks},
  url           = {https://www.aclweb.org/anthology/D18-1475},
  year          = {2018}
}
@inproceedings{yang20xformerdec,
  address       = {Online},
  author        = {Yang, Yilin  and Wang, Longyue  and Shi, Shuming  and Tadepalli, Prasad  and Lee, Stefan  and Tu, Zhaopeng},
  booktitle     = {Findings of EMNLP},
  doi           = {10.18653/v1/2020.findings-emnlp.432},
  pages         = {4799--4811},
  title         = {On the Sub-layer Functionalities of Transformer Decoder},
  url           = {https://www.aclweb.org/anthology/2020.findings-emnlp.432},
  year          = {2020}
}
@misc{ye2019bptransformer,
  archiveprefix = {arXiv},
  author        = {Zihao Ye and Qipeng Guo and Quan Gan and Xipeng Qiu and Zheng Zhang},
  eprint        = {1911.04070},
  primaryclass  = {cs.CL},
  title         = {BP-Transformer: Modelling Long-Range Context via Binary Partitioning},
  year          = {2019}
}
@article{ying21lazyformer,
  archiveprefix = {arXiv},
  author        = {Chengxuan Ying and Guolin Ke and Di He and Tie{-}Yan Liu},
  bibsource     = {dblp computer science bibliography, https://dblp.org},
  biburl        = {https://dblp.org/rec/journals/corr/abs-2102-12702.bib},
  eprint        = {2102.12702},
  journal       = {CoRR},
  timestamp     = {Tue, 02 Mar 2021 12:11:01 +0100},
  title         = {LazyFormer: Self Attention with Lazy Update},
  volume        = {abs/2102.12702},
  year          = {2021}
}
@inproceedings{you2020hardcoded,
  address       = {Online},
  author        = {You, Weiqiu  and Sun, Simeng  and Iyyer, Mohit},
  booktitle     = {Proceedings of ACL},
  doi           = {10.18653/v1/2020.acl-main.687},
  pages         = {7689--7700},
  title         = {Hard-Coded {G}aussian Attention for Neural Machine Translation},
  url           = {https://www.aclweb.org/anthology/2020.acl-main.687},
  year          = {2020}
}
@misc{zaheer2020big,
  archiveprefix = {arXiv},
  author        = {Manzil Zaheer and Guru Guruganesh and Avinava Dubey and Joshua Ainslie and Chris Alberti and Santiago Ontanon and Philip Pham and Anirudh Ravula and Qifan Wang and Li Yang and Amr Ahmed},
  eprint        = {2007.14062},
  primaryclass  = {cs.LG},
  title         = {Big Bird: Transformers for Longer Sequences},
  year          = {2020}
}
@inproceedings{zhang-etal-2018-average,
  address       = {Melbourne, Australia},
  author        = {Zhang, Biao  and Xiong, Deyi  and Su, Jinsong},
  booktitle     = {Proceedings of ACL},
  doi           = {10.18653/v1/P18-1166},
  pages         = {1789--1798},
  title         = {Accelerating Neural Transformer via an Average Attention Network},
  url           = {https://www.aclweb.org/anthology/P18-1166},
  year          = {2018}
}
@misc{he2020deberta,
  title         = {DeBERTa: Decoding-enhanced BERT with Disentangled Attention},
  author        = {Pengcheng He and Xiaodong Liu and Jianfeng Gao and Weizhu Chen},
  year          = {2020},
  eprint        = {2006.03654},
  archiveprefix = {arXiv}
}
@inproceedings{Kovaleva19bertsecret,
  author        = {Olga Kovaleva and Alexey Romanov and Anna Rogers and Anna Rumshisky},
  title         = {Revealing the Dark Secrets of {BERT}},
  booktitle     = {Proceedings of EMNLP-IJCNLP},
  pages         = {4364--4373},
  year          = {2019},
  url           = {https://doi.org/10.18653/v1/D19-1445},
  doi           = {10.18653/v1/D19-1445},
  timestamp     = {Sun, 25 Oct 2020 22:34:09 +0100},
  biburl        = {https://dblp.org/rec/conf/emnlp/KovalevaRRR19.bib},
  bibsource     = {dblp computer science bibliography, https://dblp.org}
}
@inproceedings{sabour17dynamicrouting,
  author        = {Sara Sabour and Nicholas Frosst and Geoffrey E. Hinton},
  title         = {Dynamic Routing Between Capsules},
  booktitle     = {Proceedings of NeurIPS},
  pages         = {3856--3866},
  year          = {2017},
  url           = {https://proceedings.neurips.cc/paper/2017/hash/2cad8fa47bbef282badbb8de5374b894-Abstract.html},
  timestamp     = {Thu, 21 Jan 2021 15:15:21 +0100},
  biburl        = {https://dblp.org/rec/conf/nips/SabourFH17.bib},
  bibsource     = {dblp computer science bibliography, https://dblp.org}
}
@inproceedings{hinton18emrouting,
  author        = {Geoffrey E. Hinton and Sara Sabour and Nicholas Frosst},
  title         = {Matrix capsules with {EM} routing},
  booktitle     = {Proceedings of ICLR},
  year          = {2018},
  url           = {https://openreview.net/forum?id=HJWLfGWRb},
  timestamp     = {Thu, 25 Jul 2019 14:25:47 +0200},
  biburl        = {https://dblp.org/rec/conf/iclr/HintonSF18.bib},
  bibsource     = {dblp computer science bibliography, https://dblp.org}
}
@article{shazeer19multiquery,
  author        = {Noam Shazeer},
  title         = {Fast Transformer Decoding: One Write-Head is All You Need},
  journal       = {CoRR},
  volume        = {abs/1911.02150},
  year          = {2019},
  archiveprefix = {arXiv},
  eprint        = {1911.02150},
  timestamp     = {Mon, 11 Nov 2019 18:38:09 +0100},
  biburl        = {https://dblp.org/rec/journals/corr/abs-1911-02150.bib},
  bibsource     = {dblp computer science bibliography, https://dblp.org}
}
@article{shazeer20talkinghead,
  author        = {Noam Shazeer and Zhenzhong Lan and Youlong Cheng and Nan Ding and Le Hou},
  title         = {Talking-Heads Attention},
  journal       = {CoRR},
  volume        = {abs/2003.02436},
  year          = {2020},
  archiveprefix = {arXiv},
  eprint        = {2003.02436},
  timestamp     = {Tue, 10 Mar 2020 13:33:48 +0100},
  biburl        = {https://dblp.org/rec/journals/corr/abs-2003-02436.bib},
  bibsource     = {dblp computer science bibliography, https://dblp.org}
}
@article{cordonnier20collaborate,
  author        = {Jean{-}Baptiste Cordonnier and Andreas Loukas and Martin Jaggi},
  title         = {Multi-Head Attention: Collaborate Instead of Concatenate},
  journal       = {CoRR},
  volume        = {abs/2006.16362},
  year          = {2020},
  archiveprefix = {arXiv},
  eprint        = {2006.16362},
  timestamp     = {Thu, 02 Jul 2020 14:42:48 +0200},
  biburl        = {https://dblp.org/rec/journals/corr/abs-2006-16362.bib},
  bibsource     = {dblp computer science bibliography, https://dblp.org}
}
@article{dong21notallyouneed,
  author        = {Yihe Dong and Jean{-}Baptiste Cordonnier and Andreas Loukas},
  title         = {Attention is Not All You Need: Pure Attention Loses Rank Doubly Exponentially with Depth},
  journal       = {CoRR},
  volume        = {abs/2103.03404},
  year          = {2021},
  archiveprefix = {arXiv},
  eprint        = {2103.03404},
  timestamp     = {Mon, 15 Mar 2021 17:30:55 +0100},
  biburl        = {https://dblp.org/rec/journals/corr/abs-2103-03404.bib},
  bibsource     = {dblp computer science bibliography, https://dblp.org}
}
@inproceedings{ramachandran18searching,
  author        = {Prajit Ramachandran and Barret Zoph and Quoc V. Le},
  title         = {Searching for Activation Functions},
  booktitle     = {Proceedings of ICLR},
  year          = {2018},
  url           = {https://openreview.net/forum?id=Hkuq2EkPf},
  timestamp     = {Thu, 04 Apr 2019 13:20:09 +0200},
  biburl        = {https://dblp.org/rec/conf/iclr/RamachandranZL18.bib},
  bibsource     = {dblp computer science bibliography, https://dblp.org}
}
@article{radford2018gpt,
  title         = {Improving language understanding by generative pre-training},
  author        = {Radford, Alec and Narasimhan, Karthik and Salimans, Tim and Sutskever, Ilya},
  year          = {2018}
}
@article{radford2019gpt2,
  title         = {Language Models are Unsupervised Multitask Learners},
  author        = {Radford, Alec and Wu, Jeff and Child, Rewon and Luan, David and Amodei, Dario and Sutskever, Ilya},
  year          = {2019}
}
@misc{shazeer2020glu,
  title         = {GLU Variants Improve Transformer},
  author        = {Noam Shazeer},
  year          = {2020},
  eprint        = {2002.05202},
  archiveprefix = {arXiv},
  primaryclass  = {cs.LG}
}
@inproceedings{shazeer17moe,
  author        = {Noam Shazeer and Azalia Mirhoseini and Krzysztof Maziarz and Andy Davis and Quoc V. Le and Geoffrey E. Hinton and Jeff Dean},
  title         = {Outrageously Large Neural Networks: The Sparsely-Gated Mixture-of-Experts Layer},
  booktitle     = {Proceedings of ICLR},
  year          = {2017},
  url           = {https://openreview.net/forum?id=B1ckMDqlg},
  timestamp     = {Thu, 25 Jul 2019 14:25:44 +0200},
  biburl        = {https://dblp.org/rec/conf/iclr/ShazeerMMDLHD17.bib},
  bibsource     = {dblp computer science bibliography, https://dblp.org}
}
@inproceedings{wang19learningdeep,
  author        = {Qiang Wang and Bei Li and Tong Xiao and Jingbo Zhu and Changliang Li and Derek F. Wong and Lidia S. Chao},
  title         = {Learning Deep Transformer Models for Machine Translation},
  booktitle     = {Proceedings of ACL},
  pages         = {1810--1822},
  year          = {2019},
  url           = {https://doi.org/10.18653/v1/p19-1176},
  doi           = {10.18653/v1/p19-1176},
  timestamp     = {Tue, 28 Jan 2020 10:27:53 +0100},
  biburl        = {https://dblp.org/rec/conf/acl/WangLXZLWC19.bib},
  bibsource     = {dblp computer science bibliography, https://dblp.org}
}
@inproceedings{klein-etal-2017-opennmt,
  title         = {{O}pen{NMT}: Open-Source Toolkit for Neural Machine Translation},
  author        = {Klein, Guillaume  and Kim, Yoon  and Deng, Yuntian  and Senellart, Jean  and Rush, Alexander},
  booktitle     = {Proceedings of ACL},
  month         = jul,
  year          = {2017},
  url           = {https://www.aclweb.org/anthology/P17-4012},
  pages         = {67--72}
}
@inproceedings{vaswani-etal-2018-tensor2tensor,
  title         = {{T}ensor2{T}ensor for Neural Machine Translation},
  author        = {Vaswani, Ashish  and Bengio, Samy  and Brevdo, Eugene  and Chollet, Francois  and Gomez, Aidan  and Gouws, Stephan  and Jones, Llion  and Kaiser, {\L}ukasz  and Kalchbrenner, Nal  and Parmar, Niki  and Sepassi, Ryan  and Shazeer, Noam  and Uszkoreit, Jakob},
  booktitle     = {Proceedings of AMTA},
  month         = mar,
  year          = {2018},
  url           = {https://www.aclweb.org/anthology/W18-1819},
  pages         = {193--199}
}
@inproceedings{liu20understanding,
  author        = {Liyuan Liu and Xiaodong Liu and Jianfeng Gao and Weizhu Chen and Jiawei Han},
  title         = {Understanding the Difficulty of Training Transformers},
  booktitle     = {Proceedings of EMNLP},
  pages         = {5747--5763},
  year          = {2020},
  url           = {https://doi.org/10.18653/v1/2020.emnlp-main.463},
  doi           = {10.18653/v1/2020.emnlp-main.463},
  timestamp     = {Fri, 08 Jan 2021 21:21:08 +0100},
  biburl        = {https://dblp.org/rec/conf/emnlp/LiuLGCH20.bib},
  bibsource     = {dblp computer science bibliography, https://dblp.org}
}
@inproceedings{xu19understanding,
  author        = {Jingjing Xu and Xu Sun and Zhiyuan Zhang and Guangxiang Zhao and Junyang Lin},
  title         = {Understanding and Improving Layer Normalization},
  booktitle     = {Proceedings of NeurIPS},
  pages         = {4383--4393},
  year          = {2019},
  url           = {https://proceedings.neurips.cc/paper/2019/hash/2f4fe03d77724a7217006e5d16728874-Abstract.html},
  timestamp     = {Thu, 21 Jan 2021 15:15:19 +0100},
  biburl        = {https://dblp.org/rec/conf/nips/Xu0ZZL19.bib},
  bibsource     = {dblp computer science bibliography, https://dblp.org}
}
@article{nguyen19xformerwotears,
  author        = {Toan Q. Nguyen and Julian Salazar},
  title         = {Transformers without Tears: Improving the Normalization of Self-Attention},
  journal       = {CoRR},
  volume        = {abs/1910.05895},
  year          = {2019},
  archiveprefix = {arXiv},
  eprint        = {1910.05895},
  timestamp     = {Sat, 07 Dec 2019 15:40:33 +0100},
  biburl        = {https://dblp.org/rec/journals/corr/abs-1910-05895.bib},
  bibsource     = {dblp computer science bibliography, https://dblp.org}
}
@article{ba16layernorm,
  author        = {Lei Jimmy Ba and Jamie Ryan Kiros and Geoffrey E. Hinton},
  title         = {Layer Normalization},
  journal       = {CoRR},
  volume        = {abs/1607.06450},
  year          = {2016},
  archiveprefix = {arXiv},
  eprint        = {1607.06450},
  timestamp     = {Tue, 23 Jul 2019 17:33:23 +0200},
  biburl        = {https://dblp.org/rec/journals/corr/BaKH16.bib},
  bibsource     = {dblp computer science bibliography, https://dblp.org}
}
@inproceedings{ioffe15batchnorm,
  author        = {Sergey Ioffe and Christian Szegedy},
  title         = {Batch Normalization: Accelerating Deep Network Training by Reducing Internal Covariate Shift},
  booktitle     = {Proceedings of ICML},
  pages         = {448--456},
  year          = {2015},
  url           = {http://proceedings.mlr.press/v37/ioffe15.html},
  timestamp     = {Wed, 29 May 2019 08:41:45 +0200},
  biburl        = {https://dblp.org/rec/conf/icml/IoffeS15.bib},
  bibsource     = {dblp computer science bibliography, https://dblp.org}
}
@inproceedings{pilault2021conditionally,
  title         = {Conditionally Adaptive Multi-Task Learning: Improving Transfer Learning in NLP Using Fewer Parameters {\&} Less Data},
  author        = {Jonathan Pilault and Amine El hattami and Christopher Pal},
  booktitle     = {Proceedings of ICLR},
  year          = {2021},
  url           = {https://openreview.net/forum?id=de11dbHzAMF}
}
@inproceedings{rebuffi17residualadapters,
  author        = {Sylvestre{-}Alvise Rebuffi and Hakan Bilen and Andrea Vedaldi},
  title         = {Learning multiple visual domains with residual adapters},
  booktitle     = {Proceedings of NeurIPS},
  pages         = {506--516},
  year          = {2017},
  url           = {https://proceedings.neurips.cc/paper/2017/hash/e7b24b112a44fdd9ee93bdf998c6ca0e-Abstract.html},
  timestamp     = {Thu, 21 Jan 2021 15:15:21 +0100},
  biburl        = {https://dblp.org/rec/conf/nips/RebuffiBV17.bib},
  bibsource     = {dblp computer science bibliography, https://dblp.org}
}
@inproceedings{perez18film,
  author        = {Ethan Perez and Florian Strub and Harm de Vries and Vincent Dumoulin and Aaron C. Courville},
  title         = {FiLM: Visual Reasoning with a General Conditioning Layer},
  booktitle     = {Proceedings of AAAI},
  pages         = {3942--3951},
  year          = {2018},
  url           = {https://www.aaai.org/ocs/index.php/AAAI/AAAI18/paper/view/16528},
  timestamp     = {Thu, 18 Feb 2021 14:22:23 +0100},
  biburl        = {https://dblp.org/rec/conf/aaai/PerezSVDC18.bib},
  bibsource     = {dblp computer science bibliography, https://dblp.org}
}
@misc{su2021roformer,
  title         = {RoFormer: Enhanced Transformer with Rotary Position Embedding},
  author        = {Jianlin Su and Yu Lu and Shengfeng Pan and Bo Wen and Yunfeng Liu},
  year          = {2021},
  eprint        = {2104.09864},
  archiveprefix = {arXiv}
}
@article{gu19indigo,
  author        = {Jiatao Gu and Qi Liu and Kyunghyun Cho},
  title         = {Insertion-based Decoding with Automatically Inferred Generation Order},
  journal       = {Trans. Assoc. Comput. Linguistics},
  volume        = {7},
  pages         = {661--676},
  year          = {2019},
  url           = {https://transacl.org/ojs/index.php/tacl/article/view/1732},
  timestamp     = {Wed, 17 Feb 2021 21:55:26 +0100},
  biburl        = {https://dblp.org/rec/journals/tacl/GuLC19.bib},
  bibsource     = {dblp computer science bibliography, https://dblp.org}
}
@misc{hendrycks2020gelu,
  title         = {Gaussian Error Linear Units (GELUs)},
  author        = {Dan Hendrycks and Kevin Gimpel},
  year          = {2020},
  eprint        = {1606.08415},
  archiveprefix = {arXiv},
  primaryclass  = {cs.LG}
}
@inproceedings{dauphin17glu,
  author        = {Yann N. Dauphin and Angela Fan and Michael Auli and David Grangier},
  title         = {Language Modeling with Gated Convolutional Networks},
  booktitle     = {Proceedings of ICML},
  pages         = {933--941},
  year          = {2017},
  url           = {http://proceedings.mlr.press/v70/dauphin17a.html},
  timestamp     = {Wed, 29 May 2019 08:41:45 +0200},
  biburl        = {https://dblp.org/rec/conf/icml/DauphinFAG17.bib},
  bibsource     = {dblp computer science bibliography, https://dblp.org}
}
@article{yoshida20recurrenceptm,
  author        = {Davis Yoshida and Allyson Ettinger and Kevin Gimpel},
  title         = {Adding Recurrence to Pretrained Transformers for Improved Efficiency and Context Size},
  journal       = {CoRR},
  volume        = {abs/2008.07027},
  year          = {2020},
  archiveprefix = {arXiv},
  eprint        = {2008.07027},
  timestamp     = {Fri, 21 Aug 2020 15:05:50 +0200},
  biburl        = {https://dblp.org/rec/journals/corr/abs-2008-07027.bib},
  bibsource     = {dblp computer science bibliography, https://dblp.org}
}
@inproceedings{liu-lapata-2019-hierarchical,
  title         = {Hierarchical Transformers for Multi-Document Summarization},
  author        = {Liu, Yang  and Lapata, Mirella},
  booktitle     = {Proceedings of ACL},
  month         = jul,
  year          = {2019},
  address       = {Florence, Italy},
  url           = {https://www.aclweb.org/anthology/P19-1500},
  doi           = {10.18653/v1/P19-1500},
  pages         = {5070--5081}
}
@inproceedings{zhang-etal-2019-hibert,
  title         = {{HIBERT}: Document Level Pre-training of Hierarchical Bidirectional Transformers for Document Summarization},
  author        = {Zhang, Xingxing  and Wei, Furu  and Zhou, Ming},
  booktitle     = {Proceedings of ACL},
  month         = jul,
  year          = {2019},
  address       = {Florence, Italy},
  url           = {https://www.aclweb.org/anthology/P19-1499},
  doi           = {10.18653/v1/P19-1499},
  pages         = {5059--5069}
}
@misc{zhang2021poolingformer,
  title         = {Poolingformer: Long Document Modeling with Pooling Attention},
  author        = {Hang Zhang and Yeyun Gong and Yelong Shen and Weisheng Li and Jiancheng Lv and Nan Duan and Weizhu Chen},
  year          = {2021},
  eprint        = {2105.04371},
  archiveprefix = {arXiv}
}
@article{graves16act,
  author        = {Alex Graves},
  title         = {Adaptive Computation Time for Recurrent Neural Networks},
  journal       = {CoRR},
  volume        = {abs/1603.08983},
  year          = {2016},
  archiveprefix = {arXiv},
  eprint        = {1603.08983}
}
@inproceedings{oord16dilatedcnn,
  author        = {A{\"{a}}ron van den Oord and Sander Dieleman and Heiga Zen and Karen Simonyan and Oriol Vinyals and Alex Graves and Nal Kalchbrenner and Andrew W. Senior and Koray Kavukcuoglu},
  title         = {WaveNet: {A} Generative Model for Raw Audio},
  booktitle     = {Proceedings of ISCA},
  pages         = {125},
  year          = {2016},
  url           = {http://www.isca-speech.org/archive/SSW\_2016/abstracts/ssw9\_DS-4\_van\_den\_Oord.html},
  timestamp     = {Mon, 01 Feb 2021 08:42:47 +0100},
  biburl        = {https://dblp.org/rec/conf/ssw/OordDZSVGKSK16.bib},
  bibsource     = {dblp computer science bibliography, https://dblp.org}
}
@article{ho19axialxformer,
  author        = {Jonathan Ho and Nal Kalchbrenner and Dirk Weissenborn and Tim Salimans},
  title         = {Axial Attention in Multidimensional Transformers},
  journal       = {CoRR},
  volume        = {abs/1912.12180},
  year          = {2019},
  archiveprefix = {arXiv},
  eprint        = {1912.12180},
  timestamp     = {Fri, 03 Jan 2020 16:10:45 +0100},
  biburl        = {https://dblp.org/rec/journals/corr/abs-1912-12180.bib},
  bibsource     = {dblp computer science bibliography, https://dblp.org}
}
@article{oord18cpc,
  author        = {A{\"{a}}ron van den Oord and Yazhe Li and Oriol Vinyals},
  title         = {Representation Learning with Contrastive Predictive Coding},
  journal       = {CoRR},
  volume        = {abs/1807.03748},
  year          = {2018},
  archiveprefix = {arXiv},
  eprint        = {1807.03748},
  timestamp     = {Mon, 13 Aug 2018 16:48:25 +0200},
  biburl        = {https://dblp.org/rec/journals/corr/abs-1807-03748.bib},
  bibsource     = {dblp computer science bibliography, https://dblp.org}
}
@misc{CCTransformer,
  title         = {Controlling Computation versus Quality for Neural Sequence Models},
  author        = {Ankur Bapna and Naveen Arivazhagan and Orhan Firat},
  year          = {2020},
  eprint        = {2002.07106},
  archiveprefix = {arXiv},
  primaryclass  = {cs.LG}
}
@misc{fan2021feedbackmem,
  title         = {Addressing Some Limitations of Transformers with Feedback Memory},
  author        = {Angela Fan and Thibaut Lavril and Edouard Grave and Armand Joulin and Sainbayar Sukhbaatar},
  year          = {2021},
  url           = {https://openreview.net/forum?id=OCm0rwa1lx1}
}
@misc{deebert,
  title         = {DeeBERT: Dynamic Early Exiting for Accelerating BERT Inference},
  author        = {Ji Xin and Raphael Tang and Jaejun Lee and Yaoliang Yu and Jimmy Lin},
  year          = {2020},
  eprint        = {2004.12993},
  archiveprefix = {arXiv}
}
@inproceedings{xin-etal-2020-deebert,
  title         = {{D}ee{BERT}: Dynamic Early Exiting for Accelerating {BERT} Inference},
  author        = {Xin, Ji  and Tang, Raphael  and Lee, Jaejun  and Yu, Yaoliang  and Lin, Jimmy},
  booktitle     = {Proceedings of ACL},
  month         = jul,
  year          = {2020},
  url           = {https://www.aclweb.org/anthology/2020.acl-main.204},
  doi           = {10.18653/v1/2020.acl-main.204},
  pages         = {2246--2251}
}
@misc{zhou2020bert,
  title         = {BERT Loses Patience: Fast and Robust Inference with Early Exit},
  author        = {Wangchunshu Zhou and Canwen Xu and Tao Ge and Julian McAuley and Ke Xu and Furu Wei},
  year          = {2020},
  eprint        = {2006.04152},
  archiveprefix = {arXiv}
}
@inproceedings{brown20gpt3,
  author        = {Brown, Tom and Mann, Benjamin and Ryder, Nick and Subbiah, Melanie and Kaplan, Jared D and Dhariwal, Prafulla and Neelakantan, Arvind and Shyam, Pranav and Sastry, Girish and Askell, Amanda and Agarwal, Sandhini and Herbert-Voss, Ariel and Krueger, Gretchen and Henighan, Tom and Child, Rewon and Ramesh, Aditya and Ziegler, Daniel and Wu, Jeffrey and Winter, Clemens and Hesse, Chris and Chen, Mark and Sigler, Eric and Litwin, Mateusz and Gray, Scott and Chess, Benjamin and Clark, Jack and Berner, Christopher and McCandlish, Sam and Radford, Alec and Sutskever, Ilya and Amodei, Dario},
  booktitle     = {Proceedings of NeurIPS},
  pages         = {1877--1901},
  title         = {Language Models are Few-Shot Learners},
  url           = {https://proceedings.neurips.cc/paper/2020/file/1457c0d6bfcb4967418bfb8ac142f64a-Paper.pdf},
  year          = {2020}
}
@inproceedings{sutskever14seq2seq,
  author        = {Ilya Sutskever and Oriol Vinyals and Quoc V. Le},
  title         = {Sequence to Sequence Learning with Neural Networks},
  booktitle     = {Proceedings of NeurIPS},
  pages         = {3104--3112},
  year          = {2014},
  url           = {https://proceedings.neurips.cc/paper/2014/hash/a14ac55a4f27472c5d894ec1c3c743d2-Abstract.html},
  timestamp     = {Thu, 21 Jan 2021 15:15:23 +0100},
  biburl        = {https://dblp.org/rec/conf/nips/SutskeverVL14.bib},
  bibsource     = {dblp computer science bibliography, https://dblp.org}
}
@inproceedings{carion20detr,
  author        = {Nicolas Carion and Francisco Massa and Gabriel Synnaeve and Nicolas Usunier and Alexander Kirillov and Sergey Zagoruyko},
  title         = {End-to-End Object Detection with Transformers},
  booktitle     = {Proceedings of ECCV},
  pages         = {213--229},
  year          = {2020},
  url           = {https://doi.org/10.1007/978-3-030-58452-8\_13},
  doi           = {10.1007/978-3-030-58452-8\_13},
  timestamp     = {Sat, 14 Nov 2020 00:57:07 +0100},
  biburl        = {https://dblp.org/rec/conf/eccv/CarionMSUKZ20.bib},
  bibsource     = {dblp computer science bibliography, https://dblp.org}
}
@inproceedings{he16resnet,
  author        = {Kaiming He and Xiangyu Zhang and Shaoqing Ren and Jian Sun},
  title         = {Deep Residual Learning for Image Recognition},
  booktitle     = {Proceedings CVPR},
  pages         = {770--778},
  year          = {2016},
  url           = {https://doi.org/10.1109/CVPR.2016.90},
  doi           = {10.1109/CVPR.2016.90},
  timestamp     = {Wed, 16 Oct 2019 14:14:50 +0200},
  biburl        = {https://dblp.org/rec/conf/cvpr/HeZRS16.bib},
  bibsource     = {dblp computer science bibliography, https://dblp.org}
}
@article{bachlechner20rezero,
  author        = {Thomas Bachlechner and Bodhisattwa Prasad Majumder and Huanru Henry Mao and Garrison W. Cottrell and Julian J. McAuley},
  title         = {ReZero is All You Need: Fast Convergence at Large Depth},
  journal       = {CoRR},
  volume        = {abs/2003.04887},
  year          = {2020},
  archiveprefix = {arXiv},
  eprint        = {2003.04887},
  timestamp     = {Tue, 17 Mar 2020 14:18:27 +0100},
  biburl        = {https://dblp.org/rec/journals/corr/abs-2003-04887.bib},
  bibsource     = {dblp computer science bibliography, https://dblp.org}
}
@inproceedings{wu20longshortrange,
  author        = {Zhanghao Wu and Zhijian Liu and Ji Lin and Yujun Lin and Song Han},
  title         = {Lite Transformer with Long-Short Range Attention},
  booktitle     = {Proceedings of ICLR},
  year          = {2020},
  url           = {https://openreview.net/forum?id=ByeMPlHKPH},
  timestamp     = {Thu, 11 Feb 2021 23:39:38 +0100},
  biburl        = {https://dblp.org/rec/conf/iclr/WuLLLH20.bib},
  bibsource     = {dblp computer science bibliography, https://dblp.org}
}
@article{ding2020erniedoc,
  title         = {ERNIE-DOC: The Retrospective Long-Document Modeling Transformer},
  author        = {Ding, Siyu and Shang, Junyuan and Wang, Shuohuan and Sun, Yu and Tian, Hao and Wu, Hua and Wang, Haifeng},
  year          = {2020},
  eprint        = {2012.15688},
  archiveprefix = {arXiv},
  primaryclass  = {cs.CL}
}
@inproceedings{so19evolvedxformer,
  author        = {David R. So and Quoc V. Le and Chen Liang},
  title         = {The Evolved Transformer},
  booktitle     = {Proceedings of ICML},
  pages         = {5877--5886},
  year          = {2019},
  url           = {http://proceedings.mlr.press/v97/so19a.html},
  timestamp     = {Thu, 26 Sep 2019 17:46:53 +0200},
  biburl        = {https://dblp.org/rec/conf/icml/SoLL19.bib},
  bibsource     = {dblp computer science bibliography, https://dblp.org}
}
@article{qiu2020ptms,
  author        = {Xipeng Qiu and TianXiang Sun and Yige Xu and Yunfan Shao and Ning Dai and Xuanjing Huang},
  journal       = {SCIENCE CHINA Technological Sciences},
  title         = {Pre-trained Models for Natural Language Processing: A Survey},
  year          = {2020},
  number        = {10},
  pages         = {1872â€“1897},
  volume        = {63},
  doi           = {10.1007/s11431-020-1647-3},
  publisher     = {Science China Press}
}
@article{wu21surveyonGNN,
  author        = {Zonghan Wu and Shirui Pan and Fengwen Chen and Guodong Long and Chengqi Zhang and Philip S. Yu},
  title         = {A Comprehensive Survey on Graph Neural Networks},
  journal       = {{IEEE} Trans. Neural Networks Learn. Syst.},
  volume        = {32},
  number        = {1},
  pages         = {4--24},
  year          = {2021},
  url           = {https://doi.org/10.1109/TNNLS.2020.2978386},
  doi           = {10.1109/TNNLS.2020.2978386},
  timestamp     = {Tue, 23 Mar 2021 14:12:49 +0100},
  biburl        = {https://dblp.org/rec/journals/tnn/WuPCLZY21.bib},
  bibsource     = {dblp computer science bibliography, https://dblp.org}
}
@misc{liu2019roberta,
  title         = {RoBERTa: A Robustly Optimized BERT Pretraining Approach},
  author        = {Yinhan Liu and Myle Ott and Naman Goyal and Jingfei Du and Mandar Joshi and Danqi Chen and Omer Levy and Mike Lewis and Luke Zettlemoyer and Veselin Stoyanov},
  year          = {2019},
  eprint        = {1907.11692},
  archiveprefix = {arXiv},
  primaryclass  = {cs.CL}
}
@inproceedings{lewis20bart,
  author        = {Mike Lewis and Yinhan Liu and Naman Goyal and Marjan Ghazvininejad and Abdelrahman Mohamed and Omer Levy and Veselin Stoyanov and Luke Zettlemoyer},
  title         = {{BART:} Denoising Sequence-to-Sequence Pre-training for Natural Language Generation, Translation, and Comprehension},
  booktitle     = {Proceedings of ACL},
  pages         = {7871--7880},
  year          = {2020},
  url           = {https://doi.org/10.18653/v1/2020.acl-main.703},
  doi           = {10.18653/v1/2020.acl-main.703},
  timestamp     = {Fri, 08 Jan 2021 21:20:33 +0100},
  biburl        = {https://dblp.org/rec/conf/acl/LewisLGGMLSZ20.bib},
  bibsource     = {dblp computer science bibliography, https://dblp.org}
}
@misc{li21accelerating,
  title         = {Accelerating BERT Inference for Sequence Labeling via Early-Exit},
  author        = {Xiaonan Li and Yunfan Shao and Tianxiang Sun and Hang Yan and Xipeng Qiu and Xuanjing Huang},
  year          = {2021},
  eprint        = {2105.13878},
  archiveprefix = {arXiv},
  primaryclass  = {cs.CL}
}
@misc{sun2021early,
  title         = {Early Exiting with Ensemble Internal Classifiers},
  author        = {Tianxiang Sun and Yunhua Zhou and Xiangyang Liu and Xinyu Zhang and Hao Jiang and Zhao Cao and Xuanjing Huang and Xipeng Qiu},
  year          = {2021},
  eprint        = {2105.13792},
  archiveprefix = {arXiv},
  primaryclass  = {cs.CL}
}
@inproceedings{fan-etal-2021-mask,
  title         = {Mask Attention Networks: Rethinking and Strengthen Transformer},
  author        = {Fan, Zhihao  and Gong, Yeyun  and Liu, Dayiheng  and Wei, Zhongyu  and Wang, Siyuan  and Jiao, Jian  and Duan, Nan  and Zhang, Ruofei  and Huang, Xuanjing},
  booktitle     = {Proceedings of NAACL},
  month         = jun,
  year          = {2021},
  url           = {https://www.aclweb.org/anthology/2021.naacl-main.135},
  pages         = {1692--1701}
}
@misc{shoeybi2020megatronlm,
  title         = {Megatron-LM: Training Multi-Billion Parameter Language Models Using Model Parallelism},
  author        = {Mohammad Shoeybi and Mostofa Patwary and Raul Puri and Patrick LeGresley and Jared Casper and Bryan Catanzaro},
  year          = {2020},
  eprint        = {1909.08053},
  archiveprefix = {arXiv},
  primaryclass  = {cs.CL}
}
@inproceedings{li-etal-2020-flat,
  title         = {{FLAT}: {C}hinese {NER} Using Flat-Lattice Transformer},
  author        = {Li, Xiaonan  and Yan, Hang  and Qiu, Xipeng  and Huang, Xuanjing},
  booktitle     = {Proceedings of ACL},
  month         = jul,
  year          = {2020},
  url           = {https://www.aclweb.org/anthology/2020.acl-main.611},
  doi           = {10.18653/v1/2020.acl-main.611},
  pages         = {6836--6842}
}
@misc{ma2021luna,
  title         = {Luna: Linear Unified Nested Attention},
  author        = {Xuezhe Ma and Xiang Kong and Sinong Wang and Chunting Zhou and Jonathan May and Hao Ma and Luke Zettlemoyer},
  year          = {2021},
  eprint        = {2106.01540},
  archiveprefix = {arXiv},
  primaryclass  = {cs.LG}
}
@inproceedings{chen20igpt,
  author        = {Mark Chen and Alec Radford and Rewon Child and Jeffrey Wu and Heewoo Jun and David Luan and Ilya Sutskever},
  title         = {Generative Pretraining From Pixels},
  booktitle     = {Proceedings of ICML},
  pages         = {1691--1703},
  year          = {2020},
  url           = {http://proceedings.mlr.press/v119/chen20s.html},
  timestamp     = {Tue, 15 Dec 2020 17:40:18 +0100},
  biburl        = {https://dblp.org/rec/conf/icml/ChenRC0JLS20.bib},
  bibsource     = {dblp computer science bibliography, https://dblp.org}
}
@article{zhu20deformabledetr,
  author        = {Xizhou Zhu and Weijie Su and Lewei Lu and Bin Li and Xiaogang Wang and Jifeng Dai},
  title         = {Deformable {DETR:} Deformable Transformers for End-to-End Object Detection},
  journal       = {CoRR},
  volume        = {abs/2010.04159},
  year          = {2020},
  archiveprefix = {arXiv},
  eprint        = {2010.04159},
  timestamp     = {Tue, 13 Oct 2020 15:25:23 +0200},
  biburl        = {https://dblp.org/rec/journals/corr/abs-2010-04159.bib},
  bibsource     = {dblp computer science bibliography, https://dblp.org}
}
@article{zheng20adaptiveclustering,
  author        = {Minghang Zheng and Peng Gao and Xiaogang Wang and Hongsheng Li and Hao Dong},
  title         = {End-to-End Object Detection with Adaptive Clustering Transformer},
  journal       = {CoRR},
  volume        = {abs/2011.09315},
  year          = {2020},
  archiveprefix = {arXiv},
  eprint        = {2011.09315},
  timestamp     = {Mon, 22 Mar 2021 15:29:38 +0100},
  biburl        = {https://dblp.org/rec/journals/corr/abs-2011-09315.bib},
  bibsource     = {dblp computer science bibliography, https://dblp.org}
}
@misc{jiang2021transgan,
  title         = {TransGAN: Two Transformers Can Make One Strong GAN},
  author        = {Yifan Jiang and Shiyu Chang and Zhangyang Wang},
  year          = {2021},
  eprint        = {2102.07074},
  archiveprefix = {arXiv},
  primaryclass  = {cs.CV}
}
@inproceedings{Shao_2021_WACV,
  author        = {Shao, Jie and Wen, Xin and Zhao, Bingchen and Xue, Xiangyang},
  title         = {Temporal Context Aggregation for Video Retrieval With Contrastive Learning},
  booktitle     = {Proceedings of WACV},
  month         = {January},
  year          = {2021},
  pages         = {3268--3278}
}
@misc{khan2021xformersinvision,
  title         = {Transformers in Vision: A Survey},
  author        = {Salman Khan and Muzammal Naseer and Munawar Hayat and Syed Waqas Zamir and Fahad Shahbaz Khan and Mubarak Shah},
  year          = {2021},
  eprint        = {2101.01169},
  archiveprefix = {arXiv},
  primaryclass  = {cs.CV}
}
@misc{han2021surveyvisualxformer,
  title         = {A Survey on Visual Transformer},
  author        = {Kai Han and Yunhe Wang and Hanting Chen and Xinghao Chen and Jianyuan Guo and Zhenhua Liu and Yehui Tang and An Xiao and Chunjing Xu and Yixing Xu and Zhaohui Yang and Yiman Zhang and Dacheng Tao},
  year          = {2021},
  eprint        = {2012.12556},
  archiveprefix = {arXiv},
  primaryclass  = {cs.CV}
}
@inproceedings{pham19deepsanspeech,
  author        = {Ngoc{-}Quan Pham and Thai{-}Son Nguyen and Jan Niehues and Markus M{\"{u}}ller and Alex Waibel},
  title         = {Very Deep Self-Attention Networks for End-to-End Speech Recognition},
  booktitle     = {Proceedings of Interspeech},
  pages         = {66--70},
  year          = {2019},
  url           = {https://doi.org/10.21437/Interspeech.2019-2702},
  doi           = {10.21437/Interspeech.2019-2702},
  timestamp     = {Fri, 29 Jan 2021 17:41:10 +0100},
  biburl        = {https://dblp.org/rec/conf/interspeech/PhamNN0W19.bib},
  bibsource     = {dblp computer science bibliography, https://dblp.org}
}
@inproceedings{li19xformertts,
  author        = {Naihan Li and Shujie Liu and Yanqing Liu and Sheng Zhao and Ming Liu},
  title         = {Neural Speech Synthesis with Transformer Network},
  booktitle     = {Proceedings of AAAI},
  pages         = {6706--6713},
  year          = {2019},
  url           = {https://doi.org/10.1609/aaai.v33i01.33016706},
  doi           = {10.1609/aaai.v33i01.33016706},
  timestamp     = {Tue, 02 Feb 2021 07:59:49 +0100},
  biburl        = {https://dblp.org/rec/conf/aaai/Li0LZL19.bib},
  bibsource     = {dblp computer science bibliography, https://dblp.org}
}
@inproceedings{ihm20reformertts,
  author        = {Hyeong Rae Ihm and Joun Yeop Lee and Byoung Jin Choi and Sung Jun Cheon and Nam Soo Kim},
  editor        = {Helen Meng and Bo Xu and Thomas Fang Zheng},
  title         = {Reformer-TTS: Neural Speech Synthesis with Reformer Network},
  booktitle     = {Proceedings of Interspeech},
  pages         = {2012--2016},
  year          = {2020},
  url           = {https://doi.org/10.21437/Interspeech.2020-2189},
  doi           = {10.21437/Interspeech.2020-2189},
  timestamp     = {Fri, 29 Jan 2021 17:40:52 +0100},
  biburl        = {https://dblp.org/rec/conf/interspeech/IhmLCCK20.bib},
  bibsource     = {dblp computer science bibliography, https://dblp.org}
}
@inproceedings{zheng20rnnenhancedxformer,
  author        = {Yibin Zheng and Xinhui Li and Fenglong Xie and Li Lu},
  title         = {Improving End-to-End Speech Synthesis with Local Recurrent Neural Network Enhanced Transformer},
  booktitle     = {Proceedings of ICASSP},
  pages         = {6734--6738},
  year          = {2020},
  url           = {https://doi.org/10.1109/ICASSP40776.2020.9054148},
  doi           = {10.1109/ICASSP40776.2020.9054148},
  timestamp     = {Thu, 23 Jul 2020 16:20:10 +0200},
  biburl        = {https://dblp.org/rec/conf/icassp/ZhengLXL20.bib},
  bibsource     = {dblp computer science bibliography, https://dblp.org}
}
@article{yu21se-xformer,
  author        = {Yu, Weiwei and Zhou, Jian and Wang, HuaBin and Tao, Liang},
  year          = {2021},
  month         = {02},
  title         = {SETransformer: Speech Enhancement Transformer},
  journal       = {Cognitive Computation},
  doi           = {10.1007/s12559-020-09817-2}
}
@inproceedings{kim20tgsa,
  author        = {Jaeyoung Kim and Mostafa El{-}Khamy and Jungwon Lee},
  title         = {{T-GSA:} Transformer with Gaussian-Weighted Self-Attention for Speech Enhancement},
  booktitle     = {2020 {IEEE} International Conference on Acoustics, Speech and Signal Processing, {ICASSP} 2020, Barcelona, Spain, May 4-8, 2020},
  pages         = {6649--6653},
  publisher     = {{IEEE}},
  year          = {2020},
  url           = {https://doi.org/10.1109/ICASSP40776.2020.9053591},
  doi           = {10.1109/ICASSP40776.2020.9053591},
  timestamp     = {Thu, 23 Jul 2020 16:20:10 +0200},
  biburl        = {https://dblp.org/rec/conf/icassp/KimEL20.bib},
  bibsource     = {dblp computer science bibliography, https://dblp.org}
}
@misc{lin2021m6,
  title         = {M6: A Chinese Multimodal Pretrainer},
  author        = {Junyang Lin and Rui Men and An Yang and Chang Zhou and Ming Ding and Yichang Zhang and Peng Wang and Ang Wang and Le Jiang and Xianyan Jia and Jie Zhang and Jianwei Zhang and Xu Zou and Zhikang Li and Xiaodong Deng and Jie Liu and Jinbao Xue and Huiling Zhou and Jianxin Ma and Jin Yu and Yong Li and Wei Lin and Jingren Zhou and Jie Tang and Hongxia Yang},
  year          = {2021},
  eprint        = {2103.00823},
  archiveprefix = {arXiv},
  primaryclass  = {cs.CL}
}
@article{li2020unimo,
  title         = {UNIMO: Towards Unified-Modal Understanding and Generation via Cross-Modal Contrastive Learning},
  author        = {Li, Wei and Gao, Can and Niu, Guocheng and Xiao, Xinyan and Liu, Hao and Liu, Jiachen and Wu, Hua and Wang, Haifeng},
  journal       = {arXiv preprint arXiv:2012.15409},
  year          = {2020}
}
@misc{li2019visualbert,
  title         = {VisualBERT: A Simple and Performant Baseline for Vision and Language},
  author        = {Liunian Harold Li and Mark Yatskar and Da Yin and Cho-Jui Hsieh and Kai-Wei Chang},
  year          = {2019},
  eprint        = {1908.03557},
  archiveprefix = {arXiv},
  primaryclass  = {cs.CV}
}
@inproceedings{cornia20meshedmemxformer,
  author        = {Marcella Cornia and Matteo Stefanini and Lorenzo Baraldi and Rita Cucchiara},
  title         = {Meshed-Memory Transformer for Image Captioning},
  booktitle     = {2020 {IEEE/CVF} Conference on Computer Vision and Pattern Recognition, {CVPR} 2020, Seattle, WA, USA, June 13-19, 2020},
  pages         = {10575--10584},
  publisher     = {{IEEE}},
  year          = {2020},
  url           = {https://doi.org/10.1109/CVPR42600.2020.01059},
  doi           = {10.1109/CVPR42600.2020.01059},
  timestamp     = {Tue, 11 Aug 2020 16:59:49 +0200},
  biburl        = {https://dblp.org/rec/conf/cvpr/CorniaSBC20.bib},
  bibsource     = {dblp computer science bibliography, https://dblp.org}
}
@misc{ding2021cogview,
  title         = {CogView: Mastering Text-to-Image Generation via Transformers},
  author        = {Ming Ding and Zhuoyi Yang and Wenyi Hong and Wendi Zheng and Chang Zhou and Da Yin and Junyang Lin and Xu Zou and Zhou Shao and Hongxia Yang and Jie Tang},
  year          = {2021},
  eprint        = {2105.13290},
  archiveprefix = {arXiv},
  primaryclass  = {cs.CV}
}
@misc{wu2021hitransformer,
  title         = {Hi-Transformer: Hierarchical Interactive Transformer for Efficient and Effective Long Document Modeling},
  author        = {Chuhan Wu and Fangzhao Wu and Tao Qi and Yongfeng Huang},
  year          = {2021},
  eprint        = {2106.01040},
  archiveprefix = {arXiv},
  primaryclass  = {cs.CL}
}
@misc{han2021chimera,
  title         = {Learning Shared Semantic Space for Speech-to-Text Translation},
  author        = {Chi Han and Mingxuan Wang and Heng Ji and Lei Li},
  year          = {2021},
  eprint        = {2105.03095},
  archiveprefix = {arXiv},
  primaryclass  = {cs.CL}
}
@misc{zhao2021dartsformer,
  title         = {Memory-Efficient Differentiable Transformer Architecture Search},
  author        = {Yuekai Zhao and Li Dong and Yelong Shen and Zhihua Zhang and Furu Wei and Weizhu Chen},
  year          = {2021},
  eprint        = {2105.14669},
  archiveprefix = {arXiv},
  primaryclass  = {cs.LG}
}
@misc{yang2021exploring,
  title         = {Exploring Sparse Expert Models and Beyond},
  author        = {An Yang and Junyang Lin and Rui Men and Chang Zhou and Le Jiang and Xianyan Jia and Ang Wang and Jie Zhang and Jiamang Wang and Yong Li and Di Zhang and Wei Lin and Lin Qu and Jingren Zhou and Hongxia Yang},
  year          = {2021},
  eprint        = {2105.15082},
  archiveprefix = {arXiv},
  primaryclass  = {cs.LG}
}
@inproceedings{liu2018darts,
  title         = {{DARTS}: Differentiable Architecture Search},
  author        = {Hanxiao Liu and Karen Simonyan and Yiming Yang},
  booktitle     = {Proceedings of ICLR},
  year          = {2019},
  url           = {https://openreview.net/forum?id=S1eYHoC5FX}
}
@misc{battaglia2018relational,
  title         = {Relational inductive biases, deep learning, and graph networks},
  author        = {Peter W. Battaglia and Jessica B. Hamrick and Victor Bapst and Alvaro Sanchez-Gonzalez and Vinicius Zambaldi and Mateusz Malinowski and Andrea Tacchetti and David Raposo and Adam Santoro and Ryan Faulkner and Caglar Gulcehre and Francis Song and Andrew Ballard and Justin Gilmer and George Dahl and Ashish Vaswani and Kelsey Allen and Charles Nash and Victoria Langston and Chris Dyer and Nicolas Heess and Daan Wierstra and Pushmeet Kohli and Matt Botvinick and Oriol Vinyals and Yujia Li and Razvan Pascanu},
  year          = {2018},
  eprint        = {1806.01261},
  archiveprefix = {arXiv},
  primaryclass  = {cs.LG}
}
@misc{roller2021hash,
  title         = {Hash Layers For Large Sparse Models},
  author        = {Stephen Roller and Sainbayar Sukhbaatar and Arthur Szlam and Jason Weston},
  year          = {2021},
  eprint        = {2106.04426},
  archiveprefix = {arXiv},
  primaryclass  = {cs.LG}
}
@article{lin2022survey,
  title         = {A survey of transformers},
  author        = {Lin, Tianyang and Wang, Yuxin and Liu, Xiangyang and Qiu, Xipeng},
  journal       = {AI open},
  volume        = {3},
  pages         = {111--132},
  year          = {2022},
  publisher     = {Elsevier}
}
% transformer for pinns
@inproceedings{dos2023physics,
  title         = {Physics-Informed Transformer Networks},
  author        = {Dos Santos, Fabricio and Akhound-Sadegh, Tara and Ravanbakhsh, Siamak},
  booktitle     = {The Symbiosis of Deep Learning and Differential Equations III},
  year          = {2023}
}
@article{zhang2024novel,
  title         = {A novel approach to solve hyperbolic Buckley-Leverett equation by using a transformer based physics informed neural network},
  author        = {Zhang, Feng and Nghiem, Long and Chen, Zhangxin},
  journal       = {Geoenergy Science and Engineering},
  pages         = {212711},
  year          = {2024},
  publisher     = {Elsevier}
}
@article{bragone2022physics,
  title         = {Physics-informed neural networks for modelling power transformer's dynamic thermal behaviour},
  author        = {Bragone, Federica and Morozovska, Kateryna and Hilber, Patrik and Laneryd, Tor and Luvisotto, Michele},
  journal       = {Electric power systems research},
  volume        = {211},
  pages         = {108447},
  year          = {2022},
  publisher     = {Elsevier}
}
@article{laneryd2022physics,
  title         = {Physics informed neural networks for power transformer dynamic thermal modelling},
  author        = {Laneryd, Tor and Bragone, Federica and Morozovska, Kateryna and Luvisotto, Michele},
  journal       = {IFAC-PapersOnLine},
  volume        = {55},
  number        = {20},
  pages         = {49--54},
  year          = {2022},
  publisher     = {Elsevier}
}
@article{liu2022ht,
  title         = {Ht-net: Hierarchical transformer based operator learning model for multiscale pdes},
  author        = {Liu, Xinliang and Xu, Bo and Zhang, Lei},
  year          = {2022}
}
@article{ovadia2023vito,
  title         = {Vito: Vision transformer-operator},
  author        = {Ovadia, Oded and Kahana, Adar and Stinis, Panos and Turkel, Eli and Karniadakis, George Em},
  journal       = {arXiv preprint arXiv:2303.08891},
  year          = {2023}
}
@misc{ovadia2023realtime,
  title         = {Real-time Inference and Extrapolation via a Diffusion-inspired Temporal Transformer Operator (DiTTO)},
  author        = {Oded Ovadia and Vivek Oommen and Adar Kahana and Ahmad Peyvan and Eli Turkel and George Em Karniadakis},
  year          = {2023},
  eprint        = {2307.09072},
  archiveprefix = {arXiv},
  primaryclass  = {cs.LG}
}
@inproceedings{zhang2021orthogonality,
  title         = {On orthogonality constraints for transformers},
  author        = {Zhang, Aston and Chan, Alvin and Tay, Yi and Fu, Jie and Wang, Shuohang and Zhang, Shuai and Shao, Huajie and Yao, Shuochao and Lee, Roy Ka-Wei},
  booktitle     = {Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing},
  volume        = {2},
  pages         = {375--382},
  year          = {2021},
  organization  = {Association for Computational Linguistics}
}
@inproceedings{cao,
  author        = {Cao, Shuhao},
  booktitle     = {Advances in Neural Information Processing Systems},
  editor        = {M. Ranzato and A. Beygelzimer and Y. Dauphin and P.S. Liang and J. Wortman Vaughan},
  pages         = {24924--24940},
  publisher     = {Curran Associates, Inc.},
  title         = {Choose a Transformer: Fourier or Galerkin},
  url           = {https://proceedings.neurips.cc/paper\_files/paper/2021/file/d0921d442ee91b896ad95059d13df618-Paper.pdf},
  volume        = {34},
  year          = {2021}
}
@article{nguyen2022fourierformer,
  title         = {Fourierformer: Transformer meets generalized fourier integral theorem},
  author        = {Nguyen, Tan and Pham, Minh and Nguyen, Tam and Nguyen, Khai and Osher, Stanley and Ho, Nhat},
  journal       = {Advances in Neural Information Processing Systems},
  volume        = {35},
  pages         = {29319--29335},
  year          = {2022}
}
@inproceedings{huang2019ccnet,
  title         = {Ccnet: Criss-cross attention for semantic segmentation},
  author        = {Huang, Zilong and Wang, Xinggang and Huang, Lichao and Huang, Chang and Wei, Yunchao and Liu, Wenyu},
  booktitle     = {Proceedings of the IEEE/CVF international conference on computer vision},
  pages         = {603--612},
  year          = {2019}
}
@article{kingma2014adam,
  title         = {Adam: A method for stochastic optimization},
  author        = {Kingma, Diederik P and Ba, Jimmy},
  journal       = {arXiv preprint arXiv:1412.6980},
  year          = {2014}
}
@misc{smith2018superconvergence,
  title         = {Super-Convergence: Very Fast Training of Neural Networks Using Large Learning Rates},
  author        = {Leslie N. Smith and Nicholay Topin},
  year          = {2018},
  eprint        = {1708.07120},
  archiveprefix = {arXiv},
  primaryclass  = {cs.LG}
}
